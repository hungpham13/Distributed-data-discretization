{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hungpham13/Distributed-data-discretization/blob/main/src/full_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# %cd /kaggle\n",
    "!git clone https://github.com/hungpham13/Distributed-data-discretization\n",
    "%cd Distributed-data-discretization\n",
    "!pip install -q -r requirements.txt\n",
    "%cd /content/Distributed-data-discretization/src"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-03T05:13:18.936383Z",
     "iopub.execute_input": "2023-01-03T05:13:18.936881Z",
     "iopub.status.idle": "2023-01-03T05:13:33.328941Z",
     "shell.execute_reply.started": "2023-01-03T05:13:18.936780Z",
     "shell.execute_reply": "2023-01-03T05:13:33.327495Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVN25rG6wB1d",
    "outputId": "25db2cde-1723-42a3-b419-fede4b71f9f6"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Distributed-data-discretization'...\n",
      "remote: Enumerating objects: 343, done.\u001B[K\n",
      "remote: Counting objects: 100% (120/120), done.\u001B[K\n",
      "remote: Compressing objects: 100% (81/81), done.\u001B[K\n",
      "remote: Total 343 (delta 59), reused 93 (delta 36), pack-reused 223\u001B[K\n",
      "Receiving objects: 100% (343/343), 30.42 MiB | 26.72 MiB/s, done.\n",
      "Resolving deltas: 100% (174/174), done.\n",
      "/content/Distributed-data-discretization/src\n",
      "\u001B[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test data"
   ],
   "metadata": {
    "id": "a9u8il2ywB1f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from data_generation.gen_data import generate_data\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# dists = ['normal', 'logistic', 'uniform', 'exponential', 'gamma']\n",
    "# nums_sam = [10000, 100000, 1000000, 5000000, 10000000]\n",
    "# nums_day = [183, 365, 365*3]\n",
    "dists = ['normal']\n",
    "nums_sam = [10000000]\n",
    "nums_day = [365*3]\n",
    "iter_bundle = [(num_samples, num_days, i) \n",
    "                      for num_samples in nums_sam \n",
    "                      for num_days in nums_day\n",
    "                      for i in range(1,4)\n",
    "                     ]\n",
    "\n",
    "\n",
    "for dist in dists:\n",
    "    os.makedirs(f\"/content/test-{dist}\", exist_ok=True)\n",
    "    for num_samples, num_days, i in iter_bundle[:]:\n",
    "        data = generate_data(num_days, num_samples, dist, visualize=False)\n",
    "        with open(f\"/kaggle/working/test-{dist}/test_{i}_{dist}_{num_days}_days_{num_samples}_samples.npy\", \"wb\") as f:\n",
    "            np.save(f, data)\n",
    "        del data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-02T10:58:10.725015Z",
     "iopub.execute_input": "2023-01-02T10:58:10.725430Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLMDAqdDwB1o",
    "outputId": "562b1739-d25b-48c5-fcb6-63e96e5aa962"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating normal distribution, 1095 days, 10000000 samples...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 4/1094 [02:13<10:04:43, 33.29s/it]"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train data"
   ],
   "metadata": {
    "id": "QBGjEm7VwB1p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from data.gen_data import generate_data\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# # dists = ['normal', 'logistic', 'uniform', 'exponential', 'gamma']\n",
    "# nums_sam = [1000, 3000, 10000, 30000, 100000, 300000, 1000000]\n",
    "# nums_day = [30, 60, 120, 365, 365*2, 365*3]\n",
    "# dists = ['exponential']\n",
    "# # nums_sam = [1000000]\n",
    "# # nums_day = [365*3]\n",
    "\n",
    "# for dist in dists:\n",
    "#     os.makedirs(f\"/kaggle/working/{dist}\", exist_ok=True)\n",
    "#     for num_samples in nums_sam:\n",
    "#         for num_days in nums_day:\n",
    "#             if num_samples == 1000000 and num_days == 365*3:\n",
    "#                 continue\n",
    "#             data = generate_data(num_days, num_samples, dist, visualize=False)\n",
    "#             with open(f\"/kaggle/working/{dist}/{dist}_{num_days}_days_{num_samples}_samples.npy\", \"wb\") as f:\n",
    "#                 np.save(f, data)\n",
    "#             del data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-03T05:13:33.331781Z",
     "iopub.execute_input": "2023-01-03T05:13:33.332757Z"
    },
    "trusted": true,
    "id": "s72pQmhSwB1q"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
