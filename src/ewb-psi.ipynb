{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Loading data"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.083626Z","iopub.status.busy":"2023-02-16T09:24:21.082763Z","iopub.status.idle":"2023-02-16T09:24:21.089418Z","shell.execute_reply":"2023-02-16T09:24:21.088626Z","shell.execute_reply.started":"2023-02-16T09:24:21.083570Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from time import process_time\n","from glob import glob"]},{"cell_type":"markdown","metadata":{},"source":["## Training data"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.120972Z","iopub.status.busy":"2023-02-16T09:24:21.120193Z","iopub.status.idle":"2023-02-16T09:24:21.128967Z","shell.execute_reply":"2023-02-16T09:24:21.127800Z","shell.execute_reply.started":"2023-02-16T09:24:21.120929Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(60, 551)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["train_data_path = \"../data/train/histogram/logistic_60_days_100000_samples_80.npy\"\n","train_data = np.load(train_data_path)\n","train_data.shape"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.176079Z","iopub.status.busy":"2023-02-16T09:24:21.175665Z","iopub.status.idle":"2023-02-16T09:24:21.183861Z","shell.execute_reply":"2023-02-16T09:24:21.182764Z","shell.execute_reply.started":"2023-02-16T09:24:21.176042Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["## Testing data"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.187170Z","iopub.status.busy":"2023-02-16T09:24:21.186678Z","iopub.status.idle":"2023-02-16T09:24:21.194570Z","shell.execute_reply":"2023-02-16T09:24:21.193597Z","shell.execute_reply.started":"2023-02-16T09:24:21.187134Z"},"trusted":true},"outputs":[],"source":["test_data_dir = \"../data/test/histogram\""]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.196510Z","iopub.status.busy":"2023-02-16T09:24:21.195916Z","iopub.status.idle":"2023-02-16T09:24:21.217038Z","shell.execute_reply":"2023-02-16T09:24:21.215825Z","shell.execute_reply.started":"2023-02-16T09:24:21.196475Z"},"trusted":true},"outputs":[],"source":["test_data_paths = glob(f\"{test_data_dir}/*.npy\")"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.219143Z","iopub.status.busy":"2023-02-16T09:24:21.218494Z","iopub.status.idle":"2023-02-16T09:24:21.227123Z","shell.execute_reply":"2023-02-16T09:24:21.225900Z","shell.execute_reply.started":"2023-02-16T09:24:21.219097Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]},{"data":{"text/plain":["{0: 'logistic_30_days_100000_samples_80',\n"," 1: 'logistic_30_days_1000000_samples_80',\n"," 2: 'logistic_60_days_1000000_samples_80',\n"," 3: 'logistic_183_days_100000_samples_80'}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["id2file = {}\n","for i in range(len(test_data_paths)):\n","    test_file = os.path.split(test_data_paths[i])[1].replace(\".npy\", \"\")\n","    id2file[i] = test_file\n","print(len(id2file))\n","id2file"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:21.230718Z","iopub.status.busy":"2023-02-16T09:24:21.229631Z","iopub.status.idle":"2023-02-16T09:24:22.468914Z","shell.execute_reply":"2023-02-16T09:24:22.467825Z","shell.execute_reply.started":"2023-02-16T09:24:21.230654Z"},"trusted":true},"outputs":[],"source":["test_data_all = [np.load(test_data_path) for test_data_path in test_data_paths]"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.471477Z","iopub.status.busy":"2023-02-16T09:24:22.470688Z","iopub.status.idle":"2023-02-16T09:24:22.478672Z","shell.execute_reply":"2023-02-16T09:24:22.477691Z","shell.execute_reply.started":"2023-02-16T09:24:22.471429Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(30, 551)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["test_data_all[0].shape"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Training data"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.480785Z","iopub.status.busy":"2023-02-16T09:24:22.480322Z","iopub.status.idle":"2023-02-16T09:24:22.492705Z","shell.execute_reply":"2023-02-16T09:24:22.491469Z","shell.execute_reply.started":"2023-02-16T09:24:22.480751Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(60, 550)"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["X_train = train_data[:, :-1]\n","X_train = X_train / sum(X_train[0])\n","X_train.shape"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.494671Z","iopub.status.busy":"2023-02-16T09:24:22.494233Z","iopub.status.idle":"2023-02-16T09:24:22.504585Z","shell.execute_reply":"2023-02-16T09:24:22.503638Z","shell.execute_reply.started":"2023-02-16T09:24:22.494623Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(59,)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["y_train = train_data[1:, -1]\n","y_train.shape"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.506362Z","iopub.status.busy":"2023-02-16T09:24:22.506013Z","iopub.status.idle":"2023-02-16T09:24:22.518520Z","shell.execute_reply":"2023-02-16T09:24:22.517429Z","shell.execute_reply.started":"2023-02-16T09:24:22.506331Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0: 52\n","1: 7\n"]}],"source":["print(f\"0: {len(y_train[y_train == 0])}\")\n","print(f\"1: {len(y_train[y_train == 1])}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Testing data"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.520233Z","iopub.status.busy":"2023-02-16T09:24:22.519583Z","iopub.status.idle":"2023-02-16T09:24:22.661852Z","shell.execute_reply":"2023-02-16T09:24:22.660671Z","shell.execute_reply.started":"2023-02-16T09:24:22.520199Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(30, 550)\n"]}],"source":["X_test_all = [test_data[:, :-1] / sum(test_data[0, :-1]) for test_data in test_data_all]\n","print(X_test_all[0].shape)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.665114Z","iopub.status.busy":"2023-02-16T09:24:22.664701Z","iopub.status.idle":"2023-02-16T09:24:22.678811Z","shell.execute_reply":"2023-02-16T09:24:22.677496Z","shell.execute_reply.started":"2023-02-16T09:24:22.665081Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(29,)"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["y_test_all = [test_data[1:, -1] for test_data in test_data_all]\n","y_test_all[0].shape"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.680539Z","iopub.status.busy":"2023-02-16T09:24:22.680226Z","iopub.status.idle":"2023-02-16T09:24:22.688041Z","shell.execute_reply":"2023-02-16T09:24:22.687120Z","shell.execute_reply.started":"2023-02-16T09:24:22.680510Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score, fbeta_score, confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:24:22.691413Z","iopub.status.busy":"2023-02-16T09:24:22.691037Z","iopub.status.idle":"2023-02-16T09:24:22.701329Z","shell.execute_reply":"2023-02-16T09:24:22.700198Z","shell.execute_reply.started":"2023-02-16T09:24:22.691380Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["logistic\n","60\n","100000\n","80\n"]}],"source":["train_dir_path, file_name = os.path.split(train_data_path)\n","dist, num_days, _, num_samples, _, ratio = file_name.replace(\".npy\", \"\").split(\"_\")\n","\n","print(dist)\n","print(num_days)\n","print(num_samples)\n","print(ratio)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:54:26.708253Z","iopub.status.busy":"2023-02-16T09:54:26.707793Z","iopub.status.idle":"2023-02-16T09:54:26.721663Z","shell.execute_reply":"2023-02-16T09:54:26.720445Z","shell.execute_reply.started":"2023-02-16T09:54:26.708219Z"},"trusted":true},"outputs":[],"source":["# Get cut points of EWB for histogram data\n","def equal_width_cut_points(lower_bound, upper_bound, n_bins, hist_data):\n","    for i in range(len(hist_data)):\n","        if hist_data[i] != 0:\n","            min_value = i + lower_bound\n","            break\n","    \n","    for i in range(len(hist_data) - 1, -1, -1):\n","        if hist_data[i] != 0:\n","            max_value = i + lower_bound\n","            break\n","    \n","    bin_width = (max_value - min_value) / n_bins\n","    cut_points = [round(min_value + i * bin_width) for i in range(0, n_bins + 1)]\n","    \n","    if lower_bound not in cut_points:\n","        cut_points.insert(0, lower_bound)\n","    if upper_bound not in cut_points:\n","        cut_points.append(upper_bound)\n","    \n","    return cut_points\n","\n","def equal_width_cut_points_naive(lower_bound, upper_bound, n_bins):    \n","    bin_width = (upper_bound - lower_bound) / n_bins\n","    cut_points = [round(lower_bound + i * bin_width) for i in range(0, n_bins + 1)]\n","    \n","    if lower_bound not in cut_points:\n","        cut_points.insert(0, lower_bound)\n","    if upper_bound not in cut_points:\n","        cut_points.append(upper_bound)\n","    \n","    return cut_points\n","\n","# Get cut points of EFB for histogram data\n","def equal_freq_cut_points(lower_bound, upper_bound, n_bins, hist_data):\n","    total_count = sum(hist_data)\n","    bin_size = total_count / n_bins\n","    cumulative_count = 0\n","    cut_points = []\n","    for i in range(len(hist_data)):\n","        cumulative_count += hist_data[i]\n","        if cumulative_count >= bin_size:\n","            cut_point = i + 1 + lower_bound\n","            cut_points.append(cut_point)\n","            cumulative_count = 0\n","        if len(cut_points) == n_bins - 1:\n","            break\n","    \n","    if lower_bound not in cut_points:\n","        cut_points.insert(0, lower_bound)\n","    if upper_bound not in cut_points:\n","        cut_points.append(upper_bound)\n","            \n","    return cut_points"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:54:44.565953Z","iopub.status.busy":"2023-02-16T09:54:44.565548Z","iopub.status.idle":"2023-02-16T09:57:34.732710Z","shell.execute_reply":"2023-02-16T09:57:34.731633Z","shell.execute_reply.started":"2023-02-16T09:54:44.565919Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["num_bin = 5\n","Time for solving: 2.492299999801162e-05 s\n","final_bin_edges = [300, 410, 520, 630, 740, 850] \n","\n","Best threshold: 0.04\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 0.896551724137931\n","Testing F1: 0.4\n","Testing F2: 0.3571428571428571\n","[[25  1]\n"," [ 2  1]]\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.96      0.94        26\n","           1       0.50      0.33      0.40         3\n","\n","    accuracy                           0.90        29\n","   macro avg       0.71      0.65      0.67        29\n","weighted avg       0.88      0.90      0.89        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9491525423728814\n","Testing F1: 0.888888888888889\n","Testing F2: 0.8333333333333334\n","[[44  0]\n"," [ 3 12]]\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        44\n","           1       1.00      0.80      0.89        15\n","\n","    accuracy                           0.95        59\n","   macro avg       0.97      0.90      0.93        59\n","weighted avg       0.95      0.95      0.95        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9615384615384616\n","Testing F1: 0.9014084507042254\n","Testing F2: 0.851063829787234\n","[[143   0]\n"," [  7  32]]\n","              precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.98       143\n","           1       1.00      0.82      0.90        39\n","\n","    accuracy                           0.96       182\n","   macro avg       0.98      0.91      0.94       182\n","weighted avg       0.96      0.96      0.96       182\n","\n","\n"," ############################## \n","\n","num_bin = 6\n","Time for solving: 1.0334000002387711e-05 s\n","final_bin_edges = [300, 392, 483, 575, 667, 758, 850] \n","\n","Best threshold: 0.04\n","Training Accuracy: 0.9830508474576272\n","Training F1 0.9333333333333333\n","Best Training F2 0.9722222222222222\n","[[51  1]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99        52\n","           1       0.88      1.00      0.93         7\n","\n","    accuracy                           0.98        59\n","   macro avg       0.94      0.99      0.96        59\n","weighted avg       0.99      0.98      0.98        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9835164835164835\n","Testing F1: 0.9600000000000001\n","Testing F2: 0.9375\n","[[143   0]\n"," [  3  36]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       143\n","           1       1.00      0.92      0.96        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.96      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 7\n","Time for solving: 2.2020000002953566e-05 s\n","final_bin_edges = [300, 379, 457, 536, 614, 693, 771, 850] \n","\n","Best threshold: 0.04\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 0.9310344827586207\n","Testing F1: 0.5\n","Testing F2: 0.3846153846153846\n","[[26  0]\n"," [ 2  1]]\n","              precision    recall  f1-score   support\n","\n","           0       0.93      1.00      0.96        26\n","           1       1.00      0.33      0.50         3\n","\n","    accuracy                           0.93        29\n","   macro avg       0.96      0.67      0.73        29\n","weighted avg       0.94      0.93      0.92        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9491525423728814\n","Testing F1: 0.888888888888889\n","Testing F2: 0.8333333333333334\n","[[44  0]\n"," [ 3 12]]\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        44\n","           1       1.00      0.80      0.89        15\n","\n","    accuracy                           0.95        59\n","   macro avg       0.97      0.90      0.93        59\n","weighted avg       0.95      0.95      0.95        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9395604395604396\n","Testing F1: 0.835820895522388\n","Testing F2: 0.7608695652173914\n","[[143   0]\n"," [ 11  28]]\n","              precision    recall  f1-score   support\n","\n","           0       0.93      1.00      0.96       143\n","           1       1.00      0.72      0.84        39\n","\n","    accuracy                           0.94       182\n","   macro avg       0.96      0.86      0.90       182\n","weighted avg       0.94      0.94      0.94       182\n","\n","\n"," ############################## \n","\n","num_bin = 8\n","Time for solving: 1.0346000003380595e-05 s\n","final_bin_edges = [300, 369, 438, 506, 575, 644, 712, 781, 850] \n","\n","Best threshold: 0.05\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.8\n","Testing F2: 0.7142857142857142\n","[[26  0]\n"," [ 1  2]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        26\n","           1       1.00      0.67      0.80         3\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.83      0.89        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[143   0]\n"," [  0  39]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       143\n","           1       1.00      1.00      1.00        39\n","\n","    accuracy                           1.00       182\n","   macro avg       1.00      1.00      1.00       182\n","weighted avg       1.00      1.00      1.00       182\n","\n","\n"," ############################## \n","\n","num_bin = 9\n","Time for solving: 9.400999999797932e-06 s\n","final_bin_edges = [300, 361, 422, 483, 544, 606, 667, 728, 789, 850] \n","\n","Best threshold: 0.05\n","Training Accuracy: 0.9830508474576272\n","Training F1 0.9333333333333333\n","Best Training F2 0.9722222222222222\n","[[51  1]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99        52\n","           1       0.88      1.00      0.93         7\n","\n","    accuracy                           0.98        59\n","   macro avg       0.94      0.99      0.96        59\n","weighted avg       0.99      0.98      0.98        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.978021978021978\n","Testing F1: 0.945945945945946\n","Testing F2: 0.9162303664921465\n","[[143   0]\n"," [  4  35]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.99       143\n","           1       1.00      0.90      0.95        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.95      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 10\n","Time for solving: 1.1457999995911905e-05 s\n","final_bin_edges = [300, 355, 410, 465, 520, 575, 630, 685, 740, 795, 850] \n","\n","Best threshold: 0.07\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 0.9310344827586207\n","Testing F1: 0.5\n","Testing F2: 0.3846153846153846\n","[[26  0]\n"," [ 2  1]]\n","              precision    recall  f1-score   support\n","\n","           0       0.93      1.00      0.96        26\n","           1       1.00      0.33      0.50         3\n","\n","    accuracy                           0.93        29\n","   macro avg       0.96      0.67      0.73        29\n","weighted avg       0.94      0.93      0.92        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9491525423728814\n","Testing F1: 0.888888888888889\n","Testing F2: 0.8333333333333334\n","[[44  0]\n"," [ 3 12]]\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        44\n","           1       1.00      0.80      0.89        15\n","\n","    accuracy                           0.95        59\n","   macro avg       0.97      0.90      0.93        59\n","weighted avg       0.95      0.95      0.95        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9230769230769231\n","Testing F1: 0.7812500000000001\n","Testing F2: 0.6906077348066298\n","[[143   0]\n"," [ 14  25]]\n","              precision    recall  f1-score   support\n","\n","           0       0.91      1.00      0.95       143\n","           1       1.00      0.64      0.78        39\n","\n","    accuracy                           0.92       182\n","   macro avg       0.96      0.82      0.87       182\n","weighted avg       0.93      0.92      0.92       182\n","\n","\n"," ############################## \n","\n","num_bin = 11\n","Time for solving: 9.962000000030002e-06 s\n","final_bin_edges = [300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850] \n","\n","Best threshold: 0.07\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.989010989010989\n","Testing F1: 0.9736842105263158\n","Testing F2: 0.9585492227979274\n","[[143   0]\n"," [  2  37]]\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       143\n","           1       1.00      0.95      0.97        39\n","\n","    accuracy                           0.99       182\n","   macro avg       0.99      0.97      0.98       182\n","weighted avg       0.99      0.99      0.99       182\n","\n","\n"," ############################## \n","\n","num_bin = 12\n","Time for solving: 2.957000000236576e-05 s\n","final_bin_edges = [300, 346, 392, 438, 483, 529, 575, 621, 667, 712, 758, 804, 850] \n","\n","Best threshold: 0.06\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9835164835164835\n","Testing F1: 0.9600000000000001\n","Testing F2: 0.9375\n","[[143   0]\n"," [  3  36]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       143\n","           1       1.00      0.92      0.96        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.96      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 13\n","Time for solving: 1.0190000004683952e-05 s\n","final_bin_edges = [300, 342, 385, 427, 469, 512, 554, 596, 638, 681, 723, 765, 808, 850] \n","\n","Best threshold: 0.07\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9491525423728814\n","Testing F1: 0.888888888888889\n","Testing F2: 0.8333333333333334\n","[[44  0]\n"," [ 3 12]]\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        44\n","           1       1.00      0.80      0.89        15\n","\n","    accuracy                           0.95        59\n","   macro avg       0.97      0.90      0.93        59\n","weighted avg       0.95      0.95      0.95        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9835164835164835\n","Testing F1: 0.9600000000000001\n","Testing F2: 0.9375\n","[[143   0]\n"," [  3  36]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       143\n","           1       1.00      0.92      0.96        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.96      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 14\n","Time for solving: 1.7268000000569828e-05 s\n","final_bin_edges = [300, 339, 379, 418, 457, 496, 536, 575, 614, 654, 693, 732, 771, 811, 850] \n","\n","Best threshold: 0.07\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[143   0]\n"," [  0  39]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       143\n","           1       1.00      1.00      1.00        39\n","\n","    accuracy                           1.00       182\n","   macro avg       1.00      1.00      1.00       182\n","weighted avg       1.00      1.00      1.00       182\n","\n","\n"," ############################## \n","\n","num_bin = 15\n","Time for solving: 1.0396000000412187e-05 s\n","final_bin_edges = [300, 337, 373, 410, 447, 483, 520, 557, 593, 630, 667, 703, 740, 777, 813, 850] \n","\n","Best threshold: 0.07\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.989010989010989\n","Testing F1: 0.9736842105263158\n","Testing F2: 0.9585492227979274\n","[[143   0]\n"," [  2  37]]\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       143\n","           1       1.00      0.95      0.97        39\n","\n","    accuracy                           0.99       182\n","   macro avg       0.99      0.97      0.98       182\n","weighted avg       0.99      0.99      0.99       182\n","\n","\n"," ############################## \n","\n","num_bin = 16\n","Time for solving: 1.076299999880348e-05 s\n","final_bin_edges = [300, 334, 369, 403, 438, 472, 506, 541, 575, 609, 644, 678, 712, 747, 781, 816, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9491525423728814\n","Testing F1: 0.888888888888889\n","Testing F2: 0.8333333333333334\n","[[44  0]\n"," [ 3 12]]\n","              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97        44\n","           1       1.00      0.80      0.89        15\n","\n","    accuracy                           0.95        59\n","   macro avg       0.97      0.90      0.93        59\n","weighted avg       0.95      0.95      0.95        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.967032967032967\n","Testing F1: 0.9166666666666666\n","Testing F2: 0.8730158730158731\n","[[143   0]\n"," [  6  33]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       143\n","           1       1.00      0.85      0.92        39\n","\n","    accuracy                           0.97       182\n","   macro avg       0.98      0.92      0.95       182\n","weighted avg       0.97      0.97      0.97       182\n","\n","\n"," ############################## \n","\n","num_bin = 17\n","Time for solving: 1.2547999993728354e-05 s\n","final_bin_edges = [300, 332, 365, 397, 429, 462, 494, 526, 559, 591, 624, 656, 688, 721, 753, 785, 818, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9725274725274725\n","Testing F1: 0.9315068493150686\n","Testing F2: 0.8947368421052632\n","[[143   0]\n"," [  5  34]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.98       143\n","           1       1.00      0.87      0.93        39\n","\n","    accuracy                           0.97       182\n","   macro avg       0.98      0.94      0.96       182\n","weighted avg       0.97      0.97      0.97       182\n","\n","\n"," ############################## \n","\n","num_bin = 18\n","Time for solving: 1.0396000000412187e-05 s\n","final_bin_edges = [300, 331, 361, 392, 422, 453, 483, 514, 544, 575, 606, 636, 667, 697, 728, 758, 789, 819, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9725274725274725\n","Testing F1: 0.9315068493150686\n","Testing F2: 0.8947368421052632\n","[[143   0]\n"," [  5  34]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.98       143\n","           1       1.00      0.87      0.93        39\n","\n","    accuracy                           0.97       182\n","   macro avg       0.98      0.94      0.96       182\n","weighted avg       0.97      0.97      0.97       182\n","\n","\n"," ############################## \n","\n","num_bin = 19\n","Time for solving: 1.2562999998522173e-05 s\n","final_bin_edges = [300, 329, 358, 387, 416, 445, 474, 503, 532, 561, 589, 618, 647, 676, 705, 734, 763, 792, 821, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9655172413793104\n","Testing F1: 0.9090909090909091\n","Testing F2: 0.8620689655172415\n","[[23  0]\n"," [ 1  5]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98        23\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           0.97        29\n","   macro avg       0.98      0.92      0.94        29\n","weighted avg       0.97      0.97      0.96        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9830508474576272\n","Testing F1: 0.9655172413793104\n","Testing F2: 0.9459459459459459\n","[[44  0]\n"," [ 1 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        44\n","           1       1.00      0.93      0.97        15\n","\n","    accuracy                           0.98        59\n","   macro avg       0.99      0.97      0.98        59\n","weighted avg       0.98      0.98      0.98        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.978021978021978\n","Testing F1: 0.945945945945946\n","Testing F2: 0.9162303664921465\n","[[143   0]\n"," [  4  35]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.99       143\n","           1       1.00      0.90      0.95        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.95      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 20\n","Time for solving: 2.5432000001046617e-05 s\n","final_bin_edges = [300, 328, 355, 382, 410, 438, 465, 492, 520, 548, 575, 602, 630, 658, 685, 712, 740, 768, 795, 822, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.978021978021978\n","Testing F1: 0.945945945945946\n","Testing F2: 0.9162303664921465\n","[[143   0]\n"," [  4  35]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.99       143\n","           1       1.00      0.90      0.95        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.95      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 21\n","Time for solving: 1.3404999997135292e-05 s\n","final_bin_edges = [300, 326, 352, 379, 405, 431, 457, 483, 510, 536, 562, 588, 614, 640, 667, 693, 719, 745, 771, 798, 824, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.978021978021978\n","Testing F1: 0.945945945945946\n","Testing F2: 0.9162303664921465\n","[[143   0]\n"," [  4  35]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.99       143\n","           1       1.00      0.90      0.95        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.95      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 22\n","Time for solving: 1.9436999998845295e-05 s\n","final_bin_edges = [300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 725, 750, 775, 800, 825, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9835164835164835\n","Testing F1: 0.9600000000000001\n","Testing F2: 0.9375\n","[[143   0]\n"," [  3  36]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       143\n","           1       1.00      0.92      0.96        39\n","\n","    accuracy                           0.98       182\n","   macro avg       0.99      0.96      0.97       182\n","weighted avg       0.98      0.98      0.98       182\n","\n","\n"," ############################## \n","\n","num_bin = 23\n","Time for solving: 2.409399999692141e-05 s\n","final_bin_edges = [300, 324, 348, 372, 396, 420, 443, 467, 491, 515, 539, 563, 587, 611, 635, 659, 683, 707, 730, 754, 778, 802, 826, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.9945054945054945\n","Testing F1: 0.9870129870129869\n","Testing F2: 0.9793814432989689\n","[[143   0]\n"," [  1  38]]\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       143\n","           1       1.00      0.97      0.99        39\n","\n","    accuracy                           0.99       182\n","   macro avg       1.00      0.99      0.99       182\n","weighted avg       0.99      0.99      0.99       182\n","\n","\n"," ############################## \n","\n","num_bin = 24\n","Time for solving: 1.776300000244646e-05 s\n","final_bin_edges = [300, 323, 346, 369, 392, 415, 438, 460, 483, 506, 529, 552, 575, 598, 621, 644, 667, 690, 712, 735, 758, 781, 804, 827, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.989010989010989\n","Testing F1: 0.9736842105263158\n","Testing F2: 0.9585492227979274\n","[[143   0]\n"," [  2  37]]\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       143\n","           1       1.00      0.95      0.97        39\n","\n","    accuracy                           0.99       182\n","   macro avg       0.99      0.97      0.98       182\n","weighted avg       0.99      0.99      0.99       182\n","\n","\n"," ############################## \n","\n","num_bin = 25\n","Time for solving: 1.2451999999996133e-05 s\n","final_bin_edges = [300, 322, 344, 366, 388, 410, 432, 454, 476, 498, 520, 542, 564, 586, 608, 630, 652, 674, 696, 718, 740, 762, 784, 806, 828, 850] \n","\n","Best threshold: 0.08\n","Training Accuracy: 1.0\n","Training F1 1.0\n","Best Training F2 1.0\n","[[52  0]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        52\n","           1       1.00      1.00      1.00         7\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[26  0]\n"," [ 0  3]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        26\n","           1       1.00      1.00      1.00         3\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[23  0]\n"," [ 0  6]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        23\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        29\n","   macro avg       1.00      1.00      1.00        29\n","weighted avg       1.00      1.00      1.00        29\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 1.0\n","Testing F1: 1.0\n","Testing F2: 1.0\n","[[44  0]\n"," [ 0 15]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        44\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00        59\n","   macro avg       1.00      1.00      1.00        59\n","weighted avg       1.00      1.00      1.00        59\n","\n","\n"," ############################## \n","\n","Testing Accuracy: 0.989010989010989\n","Testing F1: 0.9736842105263158\n","Testing F2: 0.9585492227979274\n","[[143   0]\n"," [  2  37]]\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       143\n","           1       1.00      0.95      0.97        39\n","\n","    accuracy                           0.99       182\n","   macro avg       0.99      0.97      0.98       182\n","weighted avg       0.99      0.99      0.99       182\n","\n","\n"," ############################## \n","\n"]}],"source":["# Array for storing results\n","results = []\n","num_bins = range(5, 26)\n","epsilon = 1e-8 # Smoothing hyperparameters\n","\n","for num_bin in num_bins:\n","    ########################\n","    ### current solution ###\n","    ########################\n","    result = [dist, num_days, num_samples, num_bin]\n","    print(f\"num_bin = {num_bin}\")\n","\n","    #########################\n","    ### Invoke the solver ###\n","    #########################\n","    start_time = process_time()\n","#     final_bin_edges = equal_width_cut_points(300, 850, num_bin, np.sum(X_train, axis=0))\n","    final_bin_edges = equal_width_cut_points_naive(300, 850, num_bin)\n","    end_time = process_time()\n","    solving_time = end_time - start_time\n","    result.append(solving_time)\n","    \n","    print(f\"Time for solving: {solving_time} s\")\n","    print(\"final_bin_edges =\", final_bin_edges, \"\\n\")\n","\n","\n","    ###############\n","    ### Evaluation ###\n","    ###############\n","    thresholds = np.arange(0.01, 1.01, 0.01)\n","    thresholds = [round(threshold, 2) for threshold in thresholds]\n","              \n","    # Training Acccuracy & F1 & F0.5\n","    num_days_train = X_train.shape[0]\n","    best_train_threshold = best_train_f2 = 0\n","    best_y_train_pred = [0] * (num_days_train - 1)\n","    train_acc = train_f1 = 0\n","    \n","    for threshold in thresholds:\n","        y_train_pred = []\n","        \n","        for i in range(num_days_train - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_train[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_train[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","      \n","            if (y_train[i] == 0 and psi < threshold) or (y_train[i] == 1 and psi >= threshold):\n","                y_train_pred.append(y_train[i])\n","            else:\n","                y_train_pred.append(1 - y_train[i])\n","        \n","        train_f2 = fbeta_score(y_train, y_train_pred, beta=2.0)\n","        if train_f2 >= best_train_f2:\n","            best_train_f2 = train_f2\n","            best_train_threshold = threshold\n","            best_y_train_pred = y_train_pred\n","            train_acc = accuracy_score(y_train, y_train_pred)\n","            train_f1 = f1_score(y_train, y_train_pred)\n","\n","    print(\"Best threshold:\", best_train_threshold)\n","    result.append(best_train_threshold)\n","\n","    print(\"Training Accuracy:\", train_acc)\n","    result.append(train_acc)\n","\n","    print(\"Training F1\", train_f1)\n","    result.append(train_f1)\n","\n","    print(\"Best Training F2\", best_train_f2)\n","    result.append(best_train_f2)    \n","\n","    print(confusion_matrix(y_train, best_y_train_pred))\n","    print(classification_report(y_train, best_y_train_pred))\n","    print()\n","              \n","    # Testing Acccuracy & F1 & F0.5\n","    for i in range(len(test_data_paths)):\n","        X_test, y_test = X_test_all[i], y_test_all[i]\n","        num_days_test = X_test.shape[0]\n","        y_test_pred = []\n","\n","        for i in range(num_days_test - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_test[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_test[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","\n","            if (y_test[i] == 0 and psi < best_train_threshold) or (y_test[i] == 1 and psi >= best_train_threshold):\n","                y_test_pred.append(y_test[i])\n","            else:\n","                y_test_pred.append(1 - y_test[i])\n","\n","        test_acc = accuracy_score(y_test, y_test_pred)\n","        result.append(test_acc)\n","        print(\"Testing Accuracy:\", test_acc)\n","\n","        test_f1 = f1_score(y_test, y_test_pred)\n","        result.append(test_f1)\n","        print(\"Testing F1:\", test_f1)\n","        \n","        test_f2 = fbeta_score(y_test, y_test_pred, beta=2.0)\n","        result.append(test_f2)\n","        print(\"Testing F2:\", test_f2)\n","\n","        print(confusion_matrix(y_test, y_test_pred))\n","        print(classification_report(y_test, y_test_pred))\n","        print(\"\\n\", \"#\"*30, \"\\n\")\n","\n","    results.append(result)"]},{"cell_type":"markdown","metadata":{},"source":["# Saving the results"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:27:22.946392Z","iopub.status.busy":"2023-02-16T09:27:22.945171Z","iopub.status.idle":"2023-02-16T09:27:22.999740Z","shell.execute_reply":"2023-02-16T09:27:22.998579Z","shell.execute_reply.started":"2023-02-16T09:27:22.946343Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>5</td>\n","      <td>0.000025</td>\n","      <td>0.04</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.896552</td>\n","      <td>...</td>\n","      <td>0.357143</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.961538</td>\n","      <td>0.901408</td>\n","      <td>0.851064</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>6</td>\n","      <td>0.000010</td>\n","      <td>0.04</td>\n","      <td>0.983051</td>\n","      <td>0.933333</td>\n","      <td>0.972222</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>7</td>\n","      <td>0.000022</td>\n","      <td>0.04</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.931034</td>\n","      <td>...</td>\n","      <td>0.384615</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.939560</td>\n","      <td>0.835821</td>\n","      <td>0.760870</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>8</td>\n","      <td>0.000010</td>\n","      <td>0.05</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>...</td>\n","      <td>0.714286</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>9</td>\n","      <td>0.000009</td>\n","      <td>0.05</td>\n","      <td>0.983051</td>\n","      <td>0.933333</td>\n","      <td>0.972222</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>10</td>\n","      <td>0.000011</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.931034</td>\n","      <td>...</td>\n","      <td>0.384615</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.923077</td>\n","      <td>0.781250</td>\n","      <td>0.690608</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>11</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>12</td>\n","      <td>0.000030</td>\n","      <td>0.06</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>13</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>14</td>\n","      <td>0.000017</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>15</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>16</td>\n","      <td>0.000011</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.967033</td>\n","      <td>0.916667</td>\n","      <td>0.873016</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>17</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.972527</td>\n","      <td>0.931507</td>\n","      <td>0.894737</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>18</td>\n","      <td>0.000010</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.972527</td>\n","      <td>0.931507</td>\n","      <td>0.894737</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>19</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>20</td>\n","      <td>0.000025</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>21</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>22</td>\n","      <td>0.000019</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>23</td>\n","      <td>0.000024</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.994505</td>\n","      <td>0.987013</td>\n","      <td>0.979381</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>24</td>\n","      <td>0.000018</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>25</td>\n","      <td>0.000012</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21 rows × 21 columns</p>\n","</div>"],"text/plain":["          0   1       2   3         4     5         6         7         8   \\\n","0   logistic  60  100000   5  0.000025  0.04  1.000000  1.000000  1.000000   \n","1   logistic  60  100000   6  0.000010  0.04  0.983051  0.933333  0.972222   \n","2   logistic  60  100000   7  0.000022  0.04  1.000000  1.000000  1.000000   \n","3   logistic  60  100000   8  0.000010  0.05  1.000000  1.000000  1.000000   \n","4   logistic  60  100000   9  0.000009  0.05  0.983051  0.933333  0.972222   \n","5   logistic  60  100000  10  0.000011  0.07  1.000000  1.000000  1.000000   \n","6   logistic  60  100000  11  0.000010  0.07  1.000000  1.000000  1.000000   \n","7   logistic  60  100000  12  0.000030  0.06  1.000000  1.000000  1.000000   \n","8   logistic  60  100000  13  0.000010  0.07  1.000000  1.000000  1.000000   \n","9   logistic  60  100000  14  0.000017  0.07  1.000000  1.000000  1.000000   \n","10  logistic  60  100000  15  0.000010  0.07  1.000000  1.000000  1.000000   \n","11  logistic  60  100000  16  0.000011  0.08  1.000000  1.000000  1.000000   \n","12  logistic  60  100000  17  0.000013  0.08  1.000000  1.000000  1.000000   \n","13  logistic  60  100000  18  0.000010  0.08  1.000000  1.000000  1.000000   \n","14  logistic  60  100000  19  0.000013  0.08  1.000000  1.000000  1.000000   \n","15  logistic  60  100000  20  0.000025  0.08  1.000000  1.000000  1.000000   \n","16  logistic  60  100000  21  0.000013  0.08  1.000000  1.000000  1.000000   \n","17  logistic  60  100000  22  0.000019  0.08  1.000000  1.000000  1.000000   \n","18  logistic  60  100000  23  0.000024  0.08  1.000000  1.000000  1.000000   \n","19  logistic  60  100000  24  0.000018  0.08  1.000000  1.000000  1.000000   \n","20  logistic  60  100000  25  0.000012  0.08  1.000000  1.000000  1.000000   \n","\n","          9   ...        11        12        13        14        15        16  \\\n","0   0.896552  ...  0.357143  1.000000  1.000000  1.000000  0.949153  0.888889   \n","1   1.000000  ...  1.000000  1.000000  1.000000  1.000000  0.983051  0.965517   \n","2   0.931034  ...  0.384615  0.965517  0.909091  0.862069  0.949153  0.888889   \n","3   0.965517  ...  0.714286  1.000000  1.000000  1.000000  0.983051  0.965517   \n","4   1.000000  ...  1.000000  0.965517  0.909091  0.862069  0.983051  0.965517   \n","5   0.931034  ...  0.384615  0.965517  0.909091  0.862069  0.949153  0.888889   \n","6   1.000000  ...  1.000000  1.000000  1.000000  1.000000  0.983051  0.965517   \n","7   1.000000  ...  1.000000  0.965517  0.909091  0.862069  0.983051  0.965517   \n","8   1.000000  ...  1.000000  0.965517  0.909091  0.862069  0.949153  0.888889   \n","9   1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","10  1.000000  ...  1.000000  0.965517  0.909091  0.862069  1.000000  1.000000   \n","11  1.000000  ...  1.000000  0.965517  0.909091  0.862069  0.949153  0.888889   \n","12  1.000000  ...  1.000000  1.000000  1.000000  1.000000  0.983051  0.965517   \n","13  1.000000  ...  1.000000  0.965517  0.909091  0.862069  1.000000  1.000000   \n","14  1.000000  ...  1.000000  0.965517  0.909091  0.862069  0.983051  0.965517   \n","15  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","16  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","17  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","18  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","19  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","20  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n","\n","          17        18        19        20  \n","0   0.833333  0.961538  0.901408  0.851064  \n","1   0.945946  0.983516  0.960000  0.937500  \n","2   0.833333  0.939560  0.835821  0.760870  \n","3   0.945946  1.000000  1.000000  1.000000  \n","4   0.945946  0.978022  0.945946  0.916230  \n","5   0.833333  0.923077  0.781250  0.690608  \n","6   0.945946  0.989011  0.973684  0.958549  \n","7   0.945946  0.983516  0.960000  0.937500  \n","8   0.833333  0.983516  0.960000  0.937500  \n","9   1.000000  1.000000  1.000000  1.000000  \n","10  1.000000  0.989011  0.973684  0.958549  \n","11  0.833333  0.967033  0.916667  0.873016  \n","12  0.945946  0.972527  0.931507  0.894737  \n","13  1.000000  0.972527  0.931507  0.894737  \n","14  0.945946  0.978022  0.945946  0.916230  \n","15  1.000000  0.978022  0.945946  0.916230  \n","16  1.000000  0.978022  0.945946  0.916230  \n","17  1.000000  0.983516  0.960000  0.937500  \n","18  1.000000  0.994505  0.987013  0.979381  \n","19  1.000000  0.989011  0.973684  0.958549  \n","20  1.000000  0.989011  0.973684  0.958549  \n","\n","[21 rows x 21 columns]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["results_df = pd.DataFrame(results)\n","results_df"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:27:23.002854Z","iopub.status.busy":"2023-02-16T09:27:23.001235Z","iopub.status.idle":"2023-02-16T09:27:23.013681Z","shell.execute_reply":"2023-02-16T09:27:23.012264Z","shell.execute_reply.started":"2023-02-16T09:27:23.002801Z"},"trusted":true},"outputs":[{"data":{"text/plain":["21"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["df_columns = [\"distribution\", \"num_days\", \"num_samples\", \"num_bin\", \"solving_time\", \n","           \"best_threshold\", \"training_acc\", \"training_f1\", \"training_f2\"]\n","\n","for i in range(len(test_data_paths)):\n","    df_columns.append(f\"{id2file[i]}_acc\")\n","    df_columns.append(f\"{id2file[i]}_f1\")\n","    df_columns.append(f\"{id2file[i]}_f2\")\n","    \n","len(df_columns)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:27:23.015714Z","iopub.status.busy":"2023-02-16T09:27:23.015224Z","iopub.status.idle":"2023-02-16T09:27:23.068466Z","shell.execute_reply":"2023-02-16T09:27:23.066944Z","shell.execute_reply.started":"2023-02-16T09:27:23.015673Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>distribution</th>\n","      <th>num_days</th>\n","      <th>num_samples</th>\n","      <th>num_bin</th>\n","      <th>solving_time</th>\n","      <th>best_threshold</th>\n","      <th>training_acc</th>\n","      <th>training_f1</th>\n","      <th>training_f2</th>\n","      <th>logistic_30_days_100000_samples_80_acc</th>\n","      <th>...</th>\n","      <th>logistic_30_days_100000_samples_80_f2</th>\n","      <th>logistic_30_days_1000000_samples_80_acc</th>\n","      <th>logistic_30_days_1000000_samples_80_f1</th>\n","      <th>logistic_30_days_1000000_samples_80_f2</th>\n","      <th>logistic_60_days_1000000_samples_80_acc</th>\n","      <th>logistic_60_days_1000000_samples_80_f1</th>\n","      <th>logistic_60_days_1000000_samples_80_f2</th>\n","      <th>logistic_183_days_100000_samples_80_acc</th>\n","      <th>logistic_183_days_100000_samples_80_f1</th>\n","      <th>logistic_183_days_100000_samples_80_f2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>5</td>\n","      <td>0.000025</td>\n","      <td>0.04</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.896552</td>\n","      <td>...</td>\n","      <td>0.357143</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.961538</td>\n","      <td>0.901408</td>\n","      <td>0.851064</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>6</td>\n","      <td>0.000010</td>\n","      <td>0.04</td>\n","      <td>0.983051</td>\n","      <td>0.933333</td>\n","      <td>0.972222</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>7</td>\n","      <td>0.000022</td>\n","      <td>0.04</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.931034</td>\n","      <td>...</td>\n","      <td>0.384615</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.939560</td>\n","      <td>0.835821</td>\n","      <td>0.760870</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>8</td>\n","      <td>0.000010</td>\n","      <td>0.05</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>...</td>\n","      <td>0.714286</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>9</td>\n","      <td>0.000009</td>\n","      <td>0.05</td>\n","      <td>0.983051</td>\n","      <td>0.933333</td>\n","      <td>0.972222</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>10</td>\n","      <td>0.000011</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.931034</td>\n","      <td>...</td>\n","      <td>0.384615</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.923077</td>\n","      <td>0.781250</td>\n","      <td>0.690608</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>11</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>12</td>\n","      <td>0.000030</td>\n","      <td>0.06</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>13</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>14</td>\n","      <td>0.000017</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>15</td>\n","      <td>0.000010</td>\n","      <td>0.07</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>16</td>\n","      <td>0.000011</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.949153</td>\n","      <td>0.888889</td>\n","      <td>0.833333</td>\n","      <td>0.967033</td>\n","      <td>0.916667</td>\n","      <td>0.873016</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>17</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.972527</td>\n","      <td>0.931507</td>\n","      <td>0.894737</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>18</td>\n","      <td>0.000010</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.972527</td>\n","      <td>0.931507</td>\n","      <td>0.894737</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>19</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.965517</td>\n","      <td>0.909091</td>\n","      <td>0.862069</td>\n","      <td>0.983051</td>\n","      <td>0.965517</td>\n","      <td>0.945946</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>20</td>\n","      <td>0.000025</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>21</td>\n","      <td>0.000013</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.978022</td>\n","      <td>0.945946</td>\n","      <td>0.916230</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>22</td>\n","      <td>0.000019</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.983516</td>\n","      <td>0.960000</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>23</td>\n","      <td>0.000024</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.994505</td>\n","      <td>0.987013</td>\n","      <td>0.979381</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>24</td>\n","      <td>0.000018</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>logistic</td>\n","      <td>60</td>\n","      <td>100000</td>\n","      <td>25</td>\n","      <td>0.000012</td>\n","      <td>0.08</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.989011</td>\n","      <td>0.973684</td>\n","      <td>0.958549</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21 rows × 21 columns</p>\n","</div>"],"text/plain":["   distribution num_days num_samples  num_bin  solving_time  best_threshold  \\\n","0      logistic       60      100000        5      0.000025            0.04   \n","1      logistic       60      100000        6      0.000010            0.04   \n","2      logistic       60      100000        7      0.000022            0.04   \n","3      logistic       60      100000        8      0.000010            0.05   \n","4      logistic       60      100000        9      0.000009            0.05   \n","5      logistic       60      100000       10      0.000011            0.07   \n","6      logistic       60      100000       11      0.000010            0.07   \n","7      logistic       60      100000       12      0.000030            0.06   \n","8      logistic       60      100000       13      0.000010            0.07   \n","9      logistic       60      100000       14      0.000017            0.07   \n","10     logistic       60      100000       15      0.000010            0.07   \n","11     logistic       60      100000       16      0.000011            0.08   \n","12     logistic       60      100000       17      0.000013            0.08   \n","13     logistic       60      100000       18      0.000010            0.08   \n","14     logistic       60      100000       19      0.000013            0.08   \n","15     logistic       60      100000       20      0.000025            0.08   \n","16     logistic       60      100000       21      0.000013            0.08   \n","17     logistic       60      100000       22      0.000019            0.08   \n","18     logistic       60      100000       23      0.000024            0.08   \n","19     logistic       60      100000       24      0.000018            0.08   \n","20     logistic       60      100000       25      0.000012            0.08   \n","\n","    training_acc  training_f1  training_f2  \\\n","0       1.000000     1.000000     1.000000   \n","1       0.983051     0.933333     0.972222   \n","2       1.000000     1.000000     1.000000   \n","3       1.000000     1.000000     1.000000   \n","4       0.983051     0.933333     0.972222   \n","5       1.000000     1.000000     1.000000   \n","6       1.000000     1.000000     1.000000   \n","7       1.000000     1.000000     1.000000   \n","8       1.000000     1.000000     1.000000   \n","9       1.000000     1.000000     1.000000   \n","10      1.000000     1.000000     1.000000   \n","11      1.000000     1.000000     1.000000   \n","12      1.000000     1.000000     1.000000   \n","13      1.000000     1.000000     1.000000   \n","14      1.000000     1.000000     1.000000   \n","15      1.000000     1.000000     1.000000   \n","16      1.000000     1.000000     1.000000   \n","17      1.000000     1.000000     1.000000   \n","18      1.000000     1.000000     1.000000   \n","19      1.000000     1.000000     1.000000   \n","20      1.000000     1.000000     1.000000   \n","\n","    logistic_30_days_100000_samples_80_acc  ...  \\\n","0                                 0.896552  ...   \n","1                                 1.000000  ...   \n","2                                 0.931034  ...   \n","3                                 0.965517  ...   \n","4                                 1.000000  ...   \n","5                                 0.931034  ...   \n","6                                 1.000000  ...   \n","7                                 1.000000  ...   \n","8                                 1.000000  ...   \n","9                                 1.000000  ...   \n","10                                1.000000  ...   \n","11                                1.000000  ...   \n","12                                1.000000  ...   \n","13                                1.000000  ...   \n","14                                1.000000  ...   \n","15                                1.000000  ...   \n","16                                1.000000  ...   \n","17                                1.000000  ...   \n","18                                1.000000  ...   \n","19                                1.000000  ...   \n","20                                1.000000  ...   \n","\n","    logistic_30_days_100000_samples_80_f2  \\\n","0                                0.357143   \n","1                                1.000000   \n","2                                0.384615   \n","3                                0.714286   \n","4                                1.000000   \n","5                                0.384615   \n","6                                1.000000   \n","7                                1.000000   \n","8                                1.000000   \n","9                                1.000000   \n","10                               1.000000   \n","11                               1.000000   \n","12                               1.000000   \n","13                               1.000000   \n","14                               1.000000   \n","15                               1.000000   \n","16                               1.000000   \n","17                               1.000000   \n","18                               1.000000   \n","19                               1.000000   \n","20                               1.000000   \n","\n","    logistic_30_days_1000000_samples_80_acc  \\\n","0                                  1.000000   \n","1                                  1.000000   \n","2                                  0.965517   \n","3                                  1.000000   \n","4                                  0.965517   \n","5                                  0.965517   \n","6                                  1.000000   \n","7                                  0.965517   \n","8                                  0.965517   \n","9                                  1.000000   \n","10                                 0.965517   \n","11                                 0.965517   \n","12                                 1.000000   \n","13                                 0.965517   \n","14                                 0.965517   \n","15                                 1.000000   \n","16                                 1.000000   \n","17                                 1.000000   \n","18                                 1.000000   \n","19                                 1.000000   \n","20                                 1.000000   \n","\n","    logistic_30_days_1000000_samples_80_f1  \\\n","0                                 1.000000   \n","1                                 1.000000   \n","2                                 0.909091   \n","3                                 1.000000   \n","4                                 0.909091   \n","5                                 0.909091   \n","6                                 1.000000   \n","7                                 0.909091   \n","8                                 0.909091   \n","9                                 1.000000   \n","10                                0.909091   \n","11                                0.909091   \n","12                                1.000000   \n","13                                0.909091   \n","14                                0.909091   \n","15                                1.000000   \n","16                                1.000000   \n","17                                1.000000   \n","18                                1.000000   \n","19                                1.000000   \n","20                                1.000000   \n","\n","    logistic_30_days_1000000_samples_80_f2  \\\n","0                                 1.000000   \n","1                                 1.000000   \n","2                                 0.862069   \n","3                                 1.000000   \n","4                                 0.862069   \n","5                                 0.862069   \n","6                                 1.000000   \n","7                                 0.862069   \n","8                                 0.862069   \n","9                                 1.000000   \n","10                                0.862069   \n","11                                0.862069   \n","12                                1.000000   \n","13                                0.862069   \n","14                                0.862069   \n","15                                1.000000   \n","16                                1.000000   \n","17                                1.000000   \n","18                                1.000000   \n","19                                1.000000   \n","20                                1.000000   \n","\n","    logistic_60_days_1000000_samples_80_acc  \\\n","0                                  0.949153   \n","1                                  0.983051   \n","2                                  0.949153   \n","3                                  0.983051   \n","4                                  0.983051   \n","5                                  0.949153   \n","6                                  0.983051   \n","7                                  0.983051   \n","8                                  0.949153   \n","9                                  1.000000   \n","10                                 1.000000   \n","11                                 0.949153   \n","12                                 0.983051   \n","13                                 1.000000   \n","14                                 0.983051   \n","15                                 1.000000   \n","16                                 1.000000   \n","17                                 1.000000   \n","18                                 1.000000   \n","19                                 1.000000   \n","20                                 1.000000   \n","\n","    logistic_60_days_1000000_samples_80_f1  \\\n","0                                 0.888889   \n","1                                 0.965517   \n","2                                 0.888889   \n","3                                 0.965517   \n","4                                 0.965517   \n","5                                 0.888889   \n","6                                 0.965517   \n","7                                 0.965517   \n","8                                 0.888889   \n","9                                 1.000000   \n","10                                1.000000   \n","11                                0.888889   \n","12                                0.965517   \n","13                                1.000000   \n","14                                0.965517   \n","15                                1.000000   \n","16                                1.000000   \n","17                                1.000000   \n","18                                1.000000   \n","19                                1.000000   \n","20                                1.000000   \n","\n","    logistic_60_days_1000000_samples_80_f2  \\\n","0                                 0.833333   \n","1                                 0.945946   \n","2                                 0.833333   \n","3                                 0.945946   \n","4                                 0.945946   \n","5                                 0.833333   \n","6                                 0.945946   \n","7                                 0.945946   \n","8                                 0.833333   \n","9                                 1.000000   \n","10                                1.000000   \n","11                                0.833333   \n","12                                0.945946   \n","13                                1.000000   \n","14                                0.945946   \n","15                                1.000000   \n","16                                1.000000   \n","17                                1.000000   \n","18                                1.000000   \n","19                                1.000000   \n","20                                1.000000   \n","\n","    logistic_183_days_100000_samples_80_acc  \\\n","0                                  0.961538   \n","1                                  0.983516   \n","2                                  0.939560   \n","3                                  1.000000   \n","4                                  0.978022   \n","5                                  0.923077   \n","6                                  0.989011   \n","7                                  0.983516   \n","8                                  0.983516   \n","9                                  1.000000   \n","10                                 0.989011   \n","11                                 0.967033   \n","12                                 0.972527   \n","13                                 0.972527   \n","14                                 0.978022   \n","15                                 0.978022   \n","16                                 0.978022   \n","17                                 0.983516   \n","18                                 0.994505   \n","19                                 0.989011   \n","20                                 0.989011   \n","\n","    logistic_183_days_100000_samples_80_f1  \\\n","0                                 0.901408   \n","1                                 0.960000   \n","2                                 0.835821   \n","3                                 1.000000   \n","4                                 0.945946   \n","5                                 0.781250   \n","6                                 0.973684   \n","7                                 0.960000   \n","8                                 0.960000   \n","9                                 1.000000   \n","10                                0.973684   \n","11                                0.916667   \n","12                                0.931507   \n","13                                0.931507   \n","14                                0.945946   \n","15                                0.945946   \n","16                                0.945946   \n","17                                0.960000   \n","18                                0.987013   \n","19                                0.973684   \n","20                                0.973684   \n","\n","    logistic_183_days_100000_samples_80_f2  \n","0                                 0.851064  \n","1                                 0.937500  \n","2                                 0.760870  \n","3                                 1.000000  \n","4                                 0.916230  \n","5                                 0.690608  \n","6                                 0.958549  \n","7                                 0.937500  \n","8                                 0.937500  \n","9                                 1.000000  \n","10                                0.958549  \n","11                                0.873016  \n","12                                0.894737  \n","13                                0.894737  \n","14                                0.916230  \n","15                                0.916230  \n","16                                0.916230  \n","17                                0.937500  \n","18                                0.979381  \n","19                                0.958549  \n","20                                0.958549  \n","\n","[21 rows x 21 columns]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["results_df.columns = df_columns\n","results_df"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:27:23.072136Z","iopub.status.busy":"2023-02-16T09:27:23.071650Z","iopub.status.idle":"2023-02-16T09:27:23.085772Z","shell.execute_reply":"2023-02-16T09:27:23.084258Z","shell.execute_reply.started":"2023-02-16T09:27:23.072090Z"},"trusted":true},"outputs":[],"source":["results_df.to_csv(\"../output/test/results.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"6aded661a7500bede91cf0cd50f9f65d386805bdb2b82378f796e1dd0d676f4e"}}},"nbformat":4,"nbformat_minor":4}
