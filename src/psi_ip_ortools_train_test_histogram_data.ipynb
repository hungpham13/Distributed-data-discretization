{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Loading data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:00:35.701854Z","iopub.status.busy":"2023-02-16T09:00:35.701414Z","iopub.status.idle":"2023-02-16T09:00:35.707848Z","shell.execute_reply":"2023-02-16T09:00:35.706265Z","shell.execute_reply.started":"2023-02-16T09:00:35.701822Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from time import process_time\n","from glob import glob\n","\n","# settings to display all columns\n","pd.set_option(\"display.max_columns\", None)"]},{"cell_type":"markdown","metadata":{},"source":["# Training data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:10.218815Z","iopub.status.busy":"2023-02-16T09:07:10.218362Z","iopub.status.idle":"2023-02-16T09:07:10.238972Z","shell.execute_reply":"2023-02-16T09:07:10.237950Z","shell.execute_reply.started":"2023-02-16T09:07:10.218776Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(365, 551)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data_path = \"../data/train/logistic/old_histogram/logistic_365_days_100000_samples_90.npy\"\n","train_data = np.load(train_data_path)\n","train_data.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:11.961306Z","iopub.status.busy":"2023-02-16T09:07:11.960850Z","iopub.status.idle":"2023-02-16T09:07:11.969003Z","shell.execute_reply":"2023-02-16T09:07:11.967670Z","shell.execute_reply.started":"2023-02-16T09:07:11.961270Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["## Testing data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:15.268145Z","iopub.status.busy":"2023-02-16T09:07:15.267159Z","iopub.status.idle":"2023-02-16T09:07:15.273682Z","shell.execute_reply":"2023-02-16T09:07:15.272400Z","shell.execute_reply.started":"2023-02-16T09:07:15.268076Z"},"trusted":true},"outputs":[],"source":["test_data_dir = \"../data/test/logistic/old_histogram\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:16.558342Z","iopub.status.busy":"2023-02-16T09:07:16.557867Z","iopub.status.idle":"2023-02-16T09:07:16.588305Z","shell.execute_reply":"2023-02-16T09:07:16.586925Z","shell.execute_reply.started":"2023-02-16T09:07:16.558291Z"},"trusted":true},"outputs":[],"source":["test_data_paths = glob(f\"{test_data_dir}/*.npy\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:17.943181Z","iopub.status.busy":"2023-02-16T09:07:17.942730Z","iopub.status.idle":"2023-02-16T09:07:17.954894Z","shell.execute_reply":"2023-02-16T09:07:17.953641Z","shell.execute_reply.started":"2023-02-16T09:07:17.943146Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{0: 'logistic_183_days_10000_samples_70',\n"," 1: 'logistic_365_days_10000_samples_90',\n"," 2: 'logistic_183_days_10000_samples_90',\n"," 3: 'logistic_365_days_10000_samples_70'}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["id2file = {}\n","for i in range(len(test_data_paths)):\n","    test_file = os.path.split(test_data_paths[i])[1].replace(\".npy\", \"\")\n","    id2file[i] = test_file\n","id2file"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:22.549588Z","iopub.status.busy":"2023-02-16T09:07:22.548896Z","iopub.status.idle":"2023-02-16T09:07:23.914669Z","shell.execute_reply":"2023-02-16T09:07:23.913303Z","shell.execute_reply.started":"2023-02-16T09:07:22.549550Z"},"trusted":true},"outputs":[],"source":["test_data_all = [np.load(test_data_path) for test_data_path in test_data_paths]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:23.918845Z","iopub.status.busy":"2023-02-16T09:07:23.917856Z","iopub.status.idle":"2023-02-16T09:07:23.926580Z","shell.execute_reply":"2023-02-16T09:07:23.925161Z","shell.execute_reply.started":"2023-02-16T09:07:23.918786Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(183, 551)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_data_all[0].shape"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:25.410770Z","iopub.status.busy":"2023-02-16T09:07:25.410340Z","iopub.status.idle":"2023-02-16T09:07:25.421573Z","shell.execute_reply":"2023-02-16T09:07:25.419682Z","shell.execute_reply.started":"2023-02-16T09:07:25.410738Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 1],\n","       [0, 0, 0, ..., 0, 0, 1]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_data_all[0]"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Training data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:33.083903Z","iopub.status.busy":"2023-02-16T09:07:33.083468Z","iopub.status.idle":"2023-02-16T09:07:33.093334Z","shell.execute_reply":"2023-02-16T09:07:33.092100Z","shell.execute_reply.started":"2023-02-16T09:07:33.083871Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(365, 550)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["X_train = train_data[:, :-1]\n","X_train = X_train / sum(X_train[0])\n","X_train.shape"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:34.734329Z","iopub.status.busy":"2023-02-16T09:07:34.733910Z","iopub.status.idle":"2023-02-16T09:07:34.742919Z","shell.execute_reply":"2023-02-16T09:07:34.741450Z","shell.execute_reply.started":"2023-02-16T09:07:34.734296Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(364,)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["y_train = train_data[1:, -1]\n","y_train.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:37.230321Z","iopub.status.busy":"2023-02-16T09:07:37.229893Z","iopub.status.idle":"2023-02-16T09:07:37.236679Z","shell.execute_reply":"2023-02-16T09:07:37.235793Z","shell.execute_reply.started":"2023-02-16T09:07:37.230288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0: 335\n","1: 29\n"]}],"source":["print(f\"0: {len(y_train[y_train == 0])}\")\n","print(f\"1: {len(y_train[y_train == 1])}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Testing data"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:40.511016Z","iopub.status.busy":"2023-02-16T09:07:40.510630Z","iopub.status.idle":"2023-02-16T09:07:40.665291Z","shell.execute_reply":"2023-02-16T09:07:40.664077Z","shell.execute_reply.started":"2023-02-16T09:07:40.510985Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(183, 550)\n"]}],"source":["X_test_all = [test_data[:, :-1] / sum(test_data[0, :-1]) for test_data in test_data_all]\n","print(X_test_all[0].shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:40.835633Z","iopub.status.busy":"2023-02-16T09:07:40.835252Z","iopub.status.idle":"2023-02-16T09:07:40.843616Z","shell.execute_reply":"2023-02-16T09:07:40.842360Z","shell.execute_reply.started":"2023-02-16T09:07:40.835604Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(182,)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["y_test_all = [test_data[1:, -1] for test_data in test_data_all]\n","y_test_all[0].shape"]},{"cell_type":"markdown","metadata":{},"source":["# Preparing data for training"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:07:52.901292Z","iopub.status.busy":"2023-02-16T09:07:52.900873Z","iopub.status.idle":"2023-02-16T09:09:29.324984Z","shell.execute_reply":"2023-02-16T09:09:29.323779Z","shell.execute_reply.started":"2023-02-16T09:07:52.901259Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Time for preparing data: 290.44382638 s\n"]}],"source":["start_time = process_time()\n","\n","\n","# Preparing interval frequencies\n","min_edge, max_edge = 300, 850\n","bin_edges = np.arange(min_edge, max_edge + 1, 1)\n","\n","train_size = len(bin_edges)\n","num_days_train = X_train.shape[0]\n","percent_days_train = np.zeros((num_days_train, train_size, train_size))\n","\n","for i in range(num_days_train):\n","    hist = X_train[i]\n","    for j in range(train_size - 1):\n","        for k in range(j + 1, train_size):\n","            percent_days_train[i, j, k] = np.sum(hist[j: k])\n","            \n","\n","# Preparing PSIs\n","epsilon = 1e-8 # Smoothing hyperparameters\n","\n","psi_train = []\n","for i in range(1, num_days_train):\n","    psi_train.append((percent_days_train[i] - percent_days_train[i - 1]) * np.log((percent_days_train[i] + epsilon) / (percent_days_train[i - 1] + epsilon)))\n","psi_train = np.array(psi_train)\n","\n","# PSI_0\n","psi_0_train = psi_train[(1 - y_train).astype(bool)]\n","psi_0_train = np.sum(psi_0_train, axis=0)\n","# Normalization\n","psi_0_train = psi_0_train / np.sum(1 - y_train)\n","\n","\n","# PSI_1\n","psi_1_train = psi_train[y_train.astype(bool)]\n","psi_1_train = np.sum(psi_1_train, axis=0)\n","# Normalization\n","psi_1_train = psi_1_train / np.sum(y_train)\n","\n","\n","end_time = process_time()\n","preparing_data_time = end_time - start_time\n","\n","print(f\"Time for preparing data: {preparing_data_time} s\")"]},{"cell_type":"markdown","metadata":{},"source":["# Models"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:29.328135Z","iopub.status.busy":"2023-02-16T09:09:29.327615Z","iopub.status.idle":"2023-02-16T09:09:29.442652Z","shell.execute_reply":"2023-02-16T09:09:29.441378Z","shell.execute_reply.started":"2023-02-16T09:09:29.328066Z"},"trusted":true},"outputs":[],"source":["from ortools.linear_solver import pywraplp"]},{"cell_type":"markdown","metadata":{},"source":["## Declare the model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:29.444297Z","iopub.status.busy":"2023-02-16T09:09:29.443951Z","iopub.status.idle":"2023-02-16T09:09:29.525870Z","shell.execute_reply":"2023-02-16T09:09:29.524939Z","shell.execute_reply.started":"2023-02-16T09:09:29.444267Z"},"trusted":true},"outputs":[],"source":["solver = pywraplp.Solver.CreateSolver('SCIP')"]},{"cell_type":"markdown","metadata":{},"source":["## Create the variables"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:29.529381Z","iopub.status.busy":"2023-02-16T09:09:29.528027Z","iopub.status.idle":"2023-02-16T09:09:30.098855Z","shell.execute_reply":"2023-02-16T09:09:30.097507Z","shell.execute_reply.started":"2023-02-16T09:09:29.529320Z"},"trusted":true},"outputs":[],"source":["x = np.empty(shape=(train_size, train_size), dtype=object)\n","\n","for i in range(train_size):\n","    for j in range(train_size):\n","        if j > i:\n","            x[i, j] = solver.IntVar(0, 1, f'x[{i}, {j}]')\n","        else:\n","            x[i, j] = 0"]},{"cell_type":"markdown","metadata":{},"source":["## Create the constraints"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:30.100711Z","iopub.status.busy":"2023-02-16T09:09:30.100347Z","iopub.status.idle":"2023-02-16T09:09:34.821063Z","shell.execute_reply":"2023-02-16T09:09:34.819816Z","shell.execute_reply.started":"2023-02-16T09:09:30.100678Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Time for creating constraints: 3.1517625459999863 s\n"]}],"source":["start_time = process_time()\n","\n","# Each row/column has at most one 1\n","# Non-overlap bins (a.k.a flow constraint)\n","for i in range(1, train_size - 1):\n","    solver.Add(solver.Sum(x[: i, i]) <= 1)\n","    solver.Add(solver.Sum(x[i, i + 1:]) <= 1)\n","    solver.Add(solver.Sum(x[: i, i]) == solver.Sum(x[i, i + 1:]))\n","    \n","# Ensure in-and-out\n","solver.Add(solver.Sum(x[0, 1:]) == 1)\n","solver.Add(solver.Sum(x[0: -1, -1]) == 1)\n","\n","# Ensure at most k bins\n","max_num_bins = 25\n","min_num_bins = 5\n","solver.Add(solver.Sum(x.flatten()) <= max_num_bins)\n","solver.Add(solver.Sum(x.flatten()) >= min_num_bins)\n","\n","end_time = process_time()\n","constraints_time = end_time - start_time\n","\n","print(f\"Time for creating constraints: {constraints_time} s\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create the objective function & Invoke the solver & Print the solution & Testing"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:34.823842Z","iopub.status.busy":"2023-02-16T09:09:34.822669Z","iopub.status.idle":"2023-02-16T09:09:35.293639Z","shell.execute_reply":"2023-02-16T09:09:35.292433Z","shell.execute_reply.started":"2023-02-16T09:09:34.823788Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def precision_0_recall_1_inverse_weighted_fbeta(y_true, y_pred, beta=2.0):\n","    precisions, recalls, fbeta_scores, supports = precision_recall_fscore_support(y_true, y_pred, beta=beta, average=None)\n","\n","    precision_0 = round(precisions[0], 4)\n","    recall_1 = round(recalls[1], 4)\n","    ratio_0, ratio_1 = supports / sum(supports)\n","    inverse_weighted_fbeta_score = round(fbeta_scores[0]*ratio_1 + fbeta_scores[1]*ratio_0, 4)\n","    \n","    return precision_0, recall_1, inverse_weighted_fbeta_score"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:09:35.295675Z","iopub.status.busy":"2023-02-16T09:09:35.295203Z","iopub.status.idle":"2023-02-16T09:09:35.303265Z","shell.execute_reply":"2023-02-16T09:09:35.301926Z","shell.execute_reply.started":"2023-02-16T09:09:35.295629Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["logistic\n","365\n","100000\n"]}],"source":["train_dir_path, file_name = os.path.split(train_data_path)\n","dist, num_days, _, num_samples, _, ratio = file_name.replace(\".npy\", \"\").split(\"_\")\n","\n","print(dist)\n","print(num_days)\n","print(num_samples)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:41:12.410910Z","iopub.status.busy":"2023-02-16T09:41:12.410504Z","iopub.status.idle":"2023-02-16T10:03:05.685681Z","shell.execute_reply":"2023-02-16T10:03:05.684306Z","shell.execute_reply.started":"2023-02-16T09:41:12.410880Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["alpha = 0.0\n","Time for solving: 375.047555188 s\n","Total cost = 0.0\n","Objective_0 = 8.168242582045924e-33\n","Objective_1 = 1.2750984459391355e-32 \n","\n","final_bin_edges = [300, 301, 302, 303, 304, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9203296703296703\n","Best Training Precision 0: 0.9203\n","Best Training Recall 1: 0.0\n","Best Training Inverse Weighted F2 0.0783\n","[[335   0]\n"," [ 29   0]]\n","Testing Accuracy: 0.7582417582417582\n","Testing Precision 0: 0.7582\n","Testing Recall 1: 0.0\n","Testing Inverse Weighted F2: 0.2273\n","[[138   0]\n"," [ 44   0]]\n","Testing Accuracy: 0.8928571428571429\n","Testing Precision 0: 0.8929\n","Testing Recall 1: 0.0\n","Testing Inverse Weighted F2: 0.1046\n","[[325   0]\n"," [ 39   0]]\n","Testing Accuracy: 0.8736263736263736\n","Testing Precision 0: 0.8736\n","Testing Recall 1: 0.0\n","Testing Inverse Weighted F2: 0.1228\n","[[159   0]\n"," [ 23   0]]\n","Testing Accuracy: 0.6593406593406593\n","Testing Precision 0: 0.6593\n","Testing Recall 1: 0.0\n","Testing Inverse Weighted F2: 0.3088\n","[[240   0]\n"," [124   0]]\n","alpha = 0.05\n"]},{"name":"stderr","output_type":"stream","text":["/home/dungnasa/anaconda3/envs/data_discretization/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/dungnasa/anaconda3/envs/data_discretization/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/dungnasa/anaconda3/envs/data_discretization/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/dungnasa/anaconda3/envs/data_discretization/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/dungnasa/anaconda3/envs/data_discretization/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Time for solving: 492.96401857399997 s\n","Total cost = 4.980994794539719e-05\n","Objective_0 = 0.00650824894276591\n","Objective_1 = 0.1246529288714602 \n","\n","final_bin_edges = [300, 303, 316, 317, 318, 320, 326, 329, 342, 349, 357, 364, 366, 367, 368, 387, 390, 392, 396, 399, 401, 402, 403, 644, 649, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9725274725274725\n","Best Training Precision 0: 0.971\n","Best Training Recall 1: 0.6552\n","Best Training Inverse Weighted F2 0.7268\n","[[335   0]\n"," [ 10  19]]\n","Testing Accuracy: 0.8296703296703297\n","Testing Precision 0: 0.8166\n","Testing Recall 1: 0.2955\n","Testing Inverse Weighted F2: 0.4921\n","[[138   0]\n"," [ 31  13]]\n","Testing Accuracy: 0.9423076923076923\n","Testing Precision 0: 0.9393\n","Testing Recall 1: 0.4615\n","Testing Inverse Weighted F2: 0.5676\n","[[325   0]\n"," [ 21  18]]\n","Testing Accuracy: 0.9505494505494505\n","Testing Precision 0: 0.9464\n","Testing Recall 1: 0.6087\n","Testing Inverse Weighted F2: 0.7019\n","[[159   0]\n"," [  9  14]]\n","Testing Accuracy: 0.782967032967033\n","Testing Precision 0: 0.7524\n","Testing Recall 1: 0.3629\n","Testing Inverse Weighted F2: 0.5938\n","[[240   0]\n"," [ 79  45]]\n","alpha = 0.1\n","Time for solving: 466.47301727800004 s\n","Total cost = 0.008633227186267295\n","Objective_0 = 0.010931288817791592\n","Objective_1 = 0.18471387122279725 \n","\n","final_bin_edges = [300, 500, 508, 525, 527, 602, 615, 617, 623, 628, 630, 634, 638, 640, 644, 647, 649, 652, 654, 657, 659, 661, 663, 665, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.989010989010989\n","Best Training Precision 0: 0.9882\n","Best Training Recall 1: 0.8621\n","Best Training Inverse Weighted F2 0.8954\n","[[335   0]\n"," [  4  25]]\n","Testing Accuracy: 0.967032967032967\n","Testing Precision 0: 0.9583\n","Testing Recall 1: 0.8636\n","Testing Inverse Weighted F2: 0.9129\n","[[138   0]\n"," [  6  38]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.976\n","Testing Recall 1: 0.7949\n","Testing Inverse Weighted F2: 0.8467\n","[[325   0]\n"," [  8  31]]\n","Testing Accuracy: 0.989010989010989\n","Testing Precision 0: 0.9876\n","Testing Recall 1: 0.913\n","Testing Inverse Weighted F2: 0.9378\n","[[159   0]\n"," [  2  21]]\n","Testing Accuracy: 0.9065934065934066\n","Testing Precision 0: 0.8759\n","Testing Recall 1: 0.7258\n","Testing Inverse Weighted F2: 0.8376\n","[[240   0]\n"," [ 34  90]]\n","alpha = 0.15\n","Time for solving: 490.4927813129998 s\n","Total cost = 0.018846534924951953\n","Objective_0 = 0.0124516003304505\n","Objective_1 = 0.19620263470556584 \n","\n","final_bin_edges = [300, 501, 525, 526, 569, 592, 602, 612, 618, 623, 628, 632, 636, 640, 644, 647, 649, 652, 655, 658, 660, 663, 667, 671, 677, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9532967032967034\n","Testing Precision 0: 0.9339\n","Testing Recall 1: 0.8629\n","Testing Inverse Weighted F2: 0.9209\n","[[240   0]\n"," [ 17 107]]\n","alpha = 0.2\n","Time for solving: 444.6063593580002 s\n","Total cost = 0.02941767313260022\n","Objective_0 = 0.0131321929136432\n","Objective_1 = 0.1996171373175739 \n","\n","final_bin_edges = [300, 569, 592, 602, 612, 618, 623, 628, 632, 636, 640, 644, 647, 649, 652, 655, 658, 660, 663, 667, 670, 675, 680, 683, 687, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.25\n","Time for solving: 460.6347532149998 s\n","Total cost = 0.04008197237136065\n","Objective_0 = 0.01325554411488558\n","Objective_1 = 0.20009452183009932 \n","\n","final_bin_edges = [300, 569, 592, 602, 612, 618, 623, 628, 632, 636, 640, 644, 647, 649, 652, 655, 658, 661, 664, 667, 670, 675, 680, 683, 691, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.3\n","Time for solving: 457.91547680199983 s\n","Total cost = 0.05075616624047632\n","Objective_0 = 0.013310677967304035\n","Objective_1 = 0.20024546939196383 \n","\n","final_bin_edges = [300, 569, 592, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 687, 693, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.35\n","Time for solving: 442.6850977420004 s\n","Total cost = 0.061433973608439725\n","Objective_0 = 0.013310677967304035\n","Objective_1 = 0.20024546939196383 \n","\n","final_bin_edges = [300, 569, 592, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 687, 693, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.4\n","Time for solving: 441.65449365499944 s\n","Total cost = 0.07211950653388433\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.45\n","Time for solving: 454.0109978520004 s\n","Total cost = 0.08280382120231031\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.5\n","Time for solving: 440.5676619219994 s\n","Total cost = 0.09348813587073634\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.55\n","Time for solving: 446.38518282899986 s\n","Total cost = 0.10417245053916235\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.6\n","Time for solving: 454.71855790100017 s\n","Total cost = 0.11485676520758832\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.65\n","Time for solving: 409.6761181130005 s\n","Total cost = 0.12554107987601434\n","Objective_0 = 0.0133550108135237\n","Objective_1 = 0.20033128255499633 \n","\n","final_bin_edges = [300, 569, 589, 602, 612, 618, 623, 628, 632, 636, 640, 644, 648, 651, 654, 658, 661, 664, 667, 670, 675, 680, 683, 690, 696, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.9725274725274725\n","Testing Precision 0: 0.965\n","Testing Recall 1: 0.8864\n","Testing Inverse Weighted F2: 0.9277\n","[[138   0]\n"," [  5  39]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9587912087912088\n","Testing Precision 0: 0.9412\n","Testing Recall 1: 0.879\n","Testing Inverse Weighted F2: 0.9304\n","[[240   0]\n"," [ 15 109]]\n","alpha = 0.7\n","Time for solving: 378.767442671 s\n","Total cost = 0.13623947233617975\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.75\n","Time for solving: 377.1627096259999 s\n","Total cost = 0.14692742462488387\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.8\n","Time for solving: 349.03838701099994 s\n","Total cost = 0.15761537691358796\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.85\n","Time for solving: 382.8162991749996 s\n","Total cost = 0.16830332920229196\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.9\n","Time for solving: 367.1799471350005 s\n","Total cost = 0.178991281490996\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 0.95\n","Time for solving: 411.37116003200026 s\n","Total cost = 0.18967923377970008\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n","alpha = 1.0\n","Time for solving: 384.50709796199953 s\n","Total cost = 0.20036718606840412\n","Objective_0 = 0.01339185970567704\n","Objective_1 = 0.20036718606840412 \n","\n","final_bin_edges = [300, 569, 589, 601, 609, 615, 622, 628, 632, 636, 640, 644, 648, 652, 655, 659, 663, 667, 670, 675, 680, 683, 687, 693, 700, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9560439560439561\n","Testing Precision 0: 0.9375\n","Testing Recall 1: 0.871\n","Testing Inverse Weighted F2: 0.9257\n","[[240   0]\n"," [ 16 108]]\n"]}],"source":["# Array fir storing results\n","results = []\n","\n","alphas = np.arange(0, 1.05, 0.05)\n","alphas = [round(alpha, 2) for alpha in alphas]\n","# alphas = [0.5, 0.9]\n","\n","for alpha in alphas:  \n","    ########################\n","    ### current solution ###\n","    ########################\n","    result = [dist, num_days, num_samples, alpha, preparing_data_time, constraints_time]\n","    print(f\"alpha = {alpha}\")\n","\n","    \n","    #######################\n","    ### Multi-objective ###\n","    #######################\n","    solver.Maximize(solver.Sum((alpha * psi_1_train * x).flatten()) - solver.Sum(((1 - alpha) * psi_0_train * x).flatten()))\n","    \n","    \n","    #########################\n","    ### Invoke the solver ###\n","    #########################\n","    start_time = process_time()\n","    status = solver.Solve()\n","    end_time = process_time()\n","    solving_time = end_time - start_time\n","    \n","    result.append(solving_time)\n","    print(f\"Time for solving: {solving_time} s\")\n","    \n","    \n","    ##########################\n","    ### Print the solution ###\n","    ##########################\n","    x_solution_value = np.zeros((train_size, train_size))\n","\n","    for i in range(train_size):\n","        for j in range(train_size):\n","            if j > i:\n","                x_solution_value[i, j] = x[i, j].solution_value()\n","                \n","    final_bin_edges = []\n","\n","    if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n","        total_cost = solver.Objective().Value()\n","        result.append(total_cost)\n","        print(f\"Total cost = {total_cost}\")\n","        \n","        objective_0 = np.sum(psi_0_train * x_solution_value)\n","        result.append(objective_0)\n","        print(f\"Objective_0 = {objective_0}\")\n","        \n","        objective_1 = np.sum(psi_1_train * x_solution_value)\n","        result.append(objective_1)\n","        print(f\"Objective_1 = {objective_1}\", \"\\n\")\n","\n","        for i in range(train_size):\n","            for j in range(train_size):\n","                if j > i and x[i, j].solution_value() == 1:\n","                    final_bin_edges.append(i + 300)\n","        final_bin_edges.append(max_edge)\n","    else:\n","        print('No solution found.')\n","        \n","    print(\"final_bin_edges =\", final_bin_edges, \"\\n\")\n","              \n","    \n","    ###############\n","    ### Evaluation ###\n","    ###############\n","    # thresholds = np.arange(0.01, 1.01, 0.01)\n","    # thresholds = [round(threshold, 2) for threshold in thresholds]\n","    thresholds = [0.1]\n","              \n","    # Training Acccuracy & F1 & F0.5\n","    num_days_train = X_train.shape[0]\n","    best_train_threshold = best_train_precision_0 = best_train_recall_1 = best_train_inverse_weighted_f2 = 0\n","    best_y_train_pred = [0] * (num_days_train - 1)\n","    train_acc = train_f1 = 0\n","    \n","    for threshold in thresholds:\n","        y_train_pred = []\n","        \n","        for i in range(num_days_train - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_train[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_train[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","      \n","            if (y_train[i] == 0 and psi < threshold) or (y_train[i] == 1 and psi >= threshold):\n","                y_train_pred.append(y_train[i])\n","            else:\n","                y_train_pred.append(1 - y_train[i])\n","        \n","        train_precision_0, train_recall_1, train_inverse_weighted_f2 = precision_0_recall_1_inverse_weighted_fbeta(y_train, y_train_pred, beta=2.0)\n","        if train_inverse_weighted_f2 > best_train_inverse_weighted_f2:\n","            best_train_inverse_weighted_f2 = train_inverse_weighted_f2\n","            best_train_threshold = threshold\n","            best_train_precision_0 = train_precision_0\n","            best_train_recall_1 = train_recall_1\n","            best_y_train_pred = y_train_pred\n","            train_acc = accuracy_score(y_train, y_train_pred)\n","\n","    print(\"Best threshold:\", best_train_threshold)\n","    result.append(best_train_threshold)\n","\n","    print(\"Training Accuracy:\", train_acc)\n","    result.append(train_acc)\n","\n","    print(\"Best Training Precision 0:\", best_train_precision_0)\n","    result.append(best_train_precision_0)   \n","\n","    print(\"Best Training Recall 1:\", best_train_recall_1)\n","    result.append(best_train_recall_1)\n","\n","    print(\"Best Training Inverse Weighted F2\", best_train_inverse_weighted_f2)\n","    result.append(best_train_inverse_weighted_f2) \n","\n","    print(confusion_matrix(y_train, best_y_train_pred))\n","              \n","    # Testing Acccuracy & F1 & F2\n","    for i in range(len(test_data_paths)):\n","        X_test, y_test = X_test_all[i], y_test_all[i]\n","        num_days_test = X_test.shape[0]\n","        y_test_pred = []\n","\n","        for i in range(num_days_test - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_test[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_test[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","\n","            if (y_test[i] == 0 and psi < best_train_threshold) or (y_test[i] == 1 and psi >= best_train_threshold):\n","                y_test_pred.append(y_test[i])\n","            else:\n","                y_test_pred.append(1 - y_test[i])\n","\n","        test_acc = accuracy_score(y_test, y_test_pred)\n","        print(\"Testing Accuracy:\", test_acc)\n","        result.append(test_acc)\n","        \n","        test_precision_0, test_recall_1, test_inverse_weighted_f2 = precision_0_recall_1_inverse_weighted_fbeta(y_test, y_test_pred, beta=2.0)\n","\n","        print(\"Testing Precision 0:\", test_precision_0)\n","        result.append(test_precision_0)   \n","\n","        print(\"Testing Recall 1:\", test_recall_1)\n","        result.append(test_recall_1)\n","\n","        print(\"Testing Inverse Weighted F2:\", test_inverse_weighted_f2)\n","        result.append(test_inverse_weighted_f2)\n","\n","        print(confusion_matrix(y_test, y_test_pred))\n","\n","    results.append(result)"]},{"cell_type":"markdown","metadata":{},"source":["# Saving the results"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:36:00.252236Z","iopub.status.busy":"2023-02-16T09:36:00.251741Z","iopub.status.idle":"2023-02-16T09:36:00.263121Z","shell.execute_reply":"2023-02-16T09:36:00.261852Z","shell.execute_reply.started":"2023-02-16T09:36:00.252201Z"},"trusted":true},"outputs":[{"data":{"text/plain":["31"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df_columns = [\"distribution\", \"num_days\", \"num_samples\", \"alpha\", \n","            \"preparing_data_time\", \"creating_constraints_time\", \"solving_time\", \n","            \"total_cost\", \"objective_0\", \"objective_1\", \"best_threshold\",\n","            \"training_acc\", \"training_precision_0\", \"training_recall_1\", \"training_inverse_weighted_f2\"]\n","\n","for i in range(len(test_data_paths)):\n","    df_columns.append(f\"{id2file[i]}_acc\")\n","    df_columns.append(f\"{id2file[i]}_precision_0\")\n","    df_columns.append(f\"{id2file[i]}_recall_1\")\n","    df_columns.append(f\"{id2file[i]}_inverse_weighted_f2\")\n","    \n","len(df_columns)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T09:36:00.267227Z","iopub.status.busy":"2023-02-16T09:36:00.266737Z","iopub.status.idle":"2023-02-16T09:36:00.309296Z","shell.execute_reply":"2023-02-16T09:36:00.308290Z","shell.execute_reply.started":"2023-02-16T09:36:00.267122Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>distribution</th>\n","      <th>num_days</th>\n","      <th>num_samples</th>\n","      <th>alpha</th>\n","      <th>preparing_data_time</th>\n","      <th>creating_constraints_time</th>\n","      <th>solving_time</th>\n","      <th>total_cost</th>\n","      <th>objective_0</th>\n","      <th>objective_1</th>\n","      <th>best_threshold</th>\n","      <th>training_acc</th>\n","      <th>training_precision_0</th>\n","      <th>training_recall_1</th>\n","      <th>training_inverse_weighted_f2</th>\n","      <th>logistic_183_days_10000_samples_70_acc</th>\n","      <th>logistic_183_days_10000_samples_70_precision_0</th>\n","      <th>logistic_183_days_10000_samples_70_recall_1</th>\n","      <th>logistic_183_days_10000_samples_70_inverse_weighted_f2</th>\n","      <th>logistic_365_days_10000_samples_90_acc</th>\n","      <th>logistic_365_days_10000_samples_90_precision_0</th>\n","      <th>logistic_365_days_10000_samples_90_recall_1</th>\n","      <th>logistic_365_days_10000_samples_90_inverse_weighted_f2</th>\n","      <th>logistic_183_days_10000_samples_90_acc</th>\n","      <th>logistic_183_days_10000_samples_90_precision_0</th>\n","      <th>logistic_183_days_10000_samples_90_recall_1</th>\n","      <th>logistic_183_days_10000_samples_90_inverse_weighted_f2</th>\n","      <th>logistic_365_days_10000_samples_70_acc</th>\n","      <th>logistic_365_days_10000_samples_70_precision_0</th>\n","      <th>logistic_365_days_10000_samples_70_recall_1</th>\n","      <th>logistic_365_days_10000_samples_70_inverse_weighted_f2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.00</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>375.047555</td>\n","      <td>0.000000</td>\n","      <td>8.168243e-33</td>\n","      <td>1.275098e-32</td>\n","      <td>0.1</td>\n","      <td>0.920330</td>\n","      <td>0.9203</td>\n","      <td>0.0000</td>\n","      <td>0.0783</td>\n","      <td>0.758242</td>\n","      <td>0.7582</td>\n","      <td>0.0000</td>\n","      <td>0.2273</td>\n","      <td>0.892857</td>\n","      <td>0.8929</td>\n","      <td>0.0000</td>\n","      <td>0.1046</td>\n","      <td>0.873626</td>\n","      <td>0.8736</td>\n","      <td>0.0000</td>\n","      <td>0.1228</td>\n","      <td>0.659341</td>\n","      <td>0.6593</td>\n","      <td>0.0000</td>\n","      <td>0.3088</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.05</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>492.964019</td>\n","      <td>0.000050</td>\n","      <td>6.508249e-03</td>\n","      <td>1.246529e-01</td>\n","      <td>0.1</td>\n","      <td>0.972527</td>\n","      <td>0.9710</td>\n","      <td>0.6552</td>\n","      <td>0.7268</td>\n","      <td>0.829670</td>\n","      <td>0.8166</td>\n","      <td>0.2955</td>\n","      <td>0.4921</td>\n","      <td>0.942308</td>\n","      <td>0.9393</td>\n","      <td>0.4615</td>\n","      <td>0.5676</td>\n","      <td>0.950549</td>\n","      <td>0.9464</td>\n","      <td>0.6087</td>\n","      <td>0.7019</td>\n","      <td>0.782967</td>\n","      <td>0.7524</td>\n","      <td>0.3629</td>\n","      <td>0.5938</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.10</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>466.473017</td>\n","      <td>0.008633</td>\n","      <td>1.093129e-02</td>\n","      <td>1.847139e-01</td>\n","      <td>0.1</td>\n","      <td>0.989011</td>\n","      <td>0.9882</td>\n","      <td>0.8621</td>\n","      <td>0.8954</td>\n","      <td>0.967033</td>\n","      <td>0.9583</td>\n","      <td>0.8636</td>\n","      <td>0.9129</td>\n","      <td>0.978022</td>\n","      <td>0.9760</td>\n","      <td>0.7949</td>\n","      <td>0.8467</td>\n","      <td>0.989011</td>\n","      <td>0.9876</td>\n","      <td>0.9130</td>\n","      <td>0.9378</td>\n","      <td>0.906593</td>\n","      <td>0.8759</td>\n","      <td>0.7258</td>\n","      <td>0.8376</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.15</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>490.492781</td>\n","      <td>0.018847</td>\n","      <td>1.245160e-02</td>\n","      <td>1.962026e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.953297</td>\n","      <td>0.9339</td>\n","      <td>0.8629</td>\n","      <td>0.9209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.20</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>444.606359</td>\n","      <td>0.029418</td>\n","      <td>1.313219e-02</td>\n","      <td>1.996171e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.25</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>460.634753</td>\n","      <td>0.040082</td>\n","      <td>1.325554e-02</td>\n","      <td>2.000945e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.30</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>457.915477</td>\n","      <td>0.050756</td>\n","      <td>1.331068e-02</td>\n","      <td>2.002455e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.35</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>442.685098</td>\n","      <td>0.061434</td>\n","      <td>1.331068e-02</td>\n","      <td>2.002455e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.40</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>441.654494</td>\n","      <td>0.072120</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.45</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>454.010998</td>\n","      <td>0.082804</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.50</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>440.567662</td>\n","      <td>0.093488</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.55</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>446.385183</td>\n","      <td>0.104172</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.60</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>454.718558</td>\n","      <td>0.114857</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.65</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>409.676118</td>\n","      <td>0.125541</td>\n","      <td>1.335501e-02</td>\n","      <td>2.003313e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.972527</td>\n","      <td>0.9650</td>\n","      <td>0.8864</td>\n","      <td>0.9277</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.958791</td>\n","      <td>0.9412</td>\n","      <td>0.8790</td>\n","      <td>0.9304</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.70</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>378.767443</td>\n","      <td>0.136239</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.75</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>377.162710</td>\n","      <td>0.146927</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.80</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>349.038387</td>\n","      <td>0.157615</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.85</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>382.816299</td>\n","      <td>0.168303</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.90</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>367.179947</td>\n","      <td>0.178991</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.95</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>411.371160</td>\n","      <td>0.189679</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>1.00</td>\n","      <td>290.443826</td>\n","      <td>3.151763</td>\n","      <td>384.507098</td>\n","      <td>0.200367</td>\n","      <td>1.339186e-02</td>\n","      <td>2.003672e-01</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.9970</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.956044</td>\n","      <td>0.9375</td>\n","      <td>0.8710</td>\n","      <td>0.9257</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   distribution num_days num_samples  alpha  preparing_data_time  \\\n","0      logistic      365      100000   0.00           290.443826   \n","1      logistic      365      100000   0.05           290.443826   \n","2      logistic      365      100000   0.10           290.443826   \n","3      logistic      365      100000   0.15           290.443826   \n","4      logistic      365      100000   0.20           290.443826   \n","5      logistic      365      100000   0.25           290.443826   \n","6      logistic      365      100000   0.30           290.443826   \n","7      logistic      365      100000   0.35           290.443826   \n","8      logistic      365      100000   0.40           290.443826   \n","9      logistic      365      100000   0.45           290.443826   \n","10     logistic      365      100000   0.50           290.443826   \n","11     logistic      365      100000   0.55           290.443826   \n","12     logistic      365      100000   0.60           290.443826   \n","13     logistic      365      100000   0.65           290.443826   \n","14     logistic      365      100000   0.70           290.443826   \n","15     logistic      365      100000   0.75           290.443826   \n","16     logistic      365      100000   0.80           290.443826   \n","17     logistic      365      100000   0.85           290.443826   \n","18     logistic      365      100000   0.90           290.443826   \n","19     logistic      365      100000   0.95           290.443826   \n","20     logistic      365      100000   1.00           290.443826   \n","\n","    creating_constraints_time  solving_time  total_cost   objective_0  \\\n","0                    3.151763    375.047555    0.000000  8.168243e-33   \n","1                    3.151763    492.964019    0.000050  6.508249e-03   \n","2                    3.151763    466.473017    0.008633  1.093129e-02   \n","3                    3.151763    490.492781    0.018847  1.245160e-02   \n","4                    3.151763    444.606359    0.029418  1.313219e-02   \n","5                    3.151763    460.634753    0.040082  1.325554e-02   \n","6                    3.151763    457.915477    0.050756  1.331068e-02   \n","7                    3.151763    442.685098    0.061434  1.331068e-02   \n","8                    3.151763    441.654494    0.072120  1.335501e-02   \n","9                    3.151763    454.010998    0.082804  1.335501e-02   \n","10                   3.151763    440.567662    0.093488  1.335501e-02   \n","11                   3.151763    446.385183    0.104172  1.335501e-02   \n","12                   3.151763    454.718558    0.114857  1.335501e-02   \n","13                   3.151763    409.676118    0.125541  1.335501e-02   \n","14                   3.151763    378.767443    0.136239  1.339186e-02   \n","15                   3.151763    377.162710    0.146927  1.339186e-02   \n","16                   3.151763    349.038387    0.157615  1.339186e-02   \n","17                   3.151763    382.816299    0.168303  1.339186e-02   \n","18                   3.151763    367.179947    0.178991  1.339186e-02   \n","19                   3.151763    411.371160    0.189679  1.339186e-02   \n","20                   3.151763    384.507098    0.200367  1.339186e-02   \n","\n","     objective_1  best_threshold  training_acc  training_precision_0  \\\n","0   1.275098e-32             0.1      0.920330                0.9203   \n","1   1.246529e-01             0.1      0.972527                0.9710   \n","2   1.847139e-01             0.1      0.989011                0.9882   \n","3   1.962026e-01             0.1      0.997253                0.9970   \n","4   1.996171e-01             0.1      0.997253                0.9970   \n","5   2.000945e-01             0.1      0.997253                0.9970   \n","6   2.002455e-01             0.1      0.997253                0.9970   \n","7   2.002455e-01             0.1      0.997253                0.9970   \n","8   2.003313e-01             0.1      0.997253                0.9970   \n","9   2.003313e-01             0.1      0.997253                0.9970   \n","10  2.003313e-01             0.1      0.997253                0.9970   \n","11  2.003313e-01             0.1      0.997253                0.9970   \n","12  2.003313e-01             0.1      0.997253                0.9970   \n","13  2.003313e-01             0.1      0.997253                0.9970   \n","14  2.003672e-01             0.1      0.997253                0.9970   \n","15  2.003672e-01             0.1      0.997253                0.9970   \n","16  2.003672e-01             0.1      0.997253                0.9970   \n","17  2.003672e-01             0.1      0.997253                0.9970   \n","18  2.003672e-01             0.1      0.997253                0.9970   \n","19  2.003672e-01             0.1      0.997253                0.9970   \n","20  2.003672e-01             0.1      0.997253                0.9970   \n","\n","    training_recall_1  training_inverse_weighted_f2  \\\n","0              0.0000                        0.0783   \n","1              0.6552                        0.7268   \n","2              0.8621                        0.8954   \n","3              0.9655                        0.9744   \n","4              0.9655                        0.9744   \n","5              0.9655                        0.9744   \n","6              0.9655                        0.9744   \n","7              0.9655                        0.9744   \n","8              0.9655                        0.9744   \n","9              0.9655                        0.9744   \n","10             0.9655                        0.9744   \n","11             0.9655                        0.9744   \n","12             0.9655                        0.9744   \n","13             0.9655                        0.9744   \n","14             0.9655                        0.9744   \n","15             0.9655                        0.9744   \n","16             0.9655                        0.9744   \n","17             0.9655                        0.9744   \n","18             0.9655                        0.9744   \n","19             0.9655                        0.9744   \n","20             0.9655                        0.9744   \n","\n","    logistic_183_days_10000_samples_70_acc  \\\n","0                                 0.758242   \n","1                                 0.829670   \n","2                                 0.967033   \n","3                                 0.978022   \n","4                                 0.978022   \n","5                                 0.972527   \n","6                                 0.972527   \n","7                                 0.972527   \n","8                                 0.972527   \n","9                                 0.972527   \n","10                                0.972527   \n","11                                0.972527   \n","12                                0.972527   \n","13                                0.972527   \n","14                                0.978022   \n","15                                0.978022   \n","16                                0.978022   \n","17                                0.978022   \n","18                                0.978022   \n","19                                0.978022   \n","20                                0.978022   \n","\n","    logistic_183_days_10000_samples_70_precision_0  \\\n","0                                           0.7582   \n","1                                           0.8166   \n","2                                           0.9583   \n","3                                           0.9718   \n","4                                           0.9718   \n","5                                           0.9650   \n","6                                           0.9650   \n","7                                           0.9650   \n","8                                           0.9650   \n","9                                           0.9650   \n","10                                          0.9650   \n","11                                          0.9650   \n","12                                          0.9650   \n","13                                          0.9650   \n","14                                          0.9718   \n","15                                          0.9718   \n","16                                          0.9718   \n","17                                          0.9718   \n","18                                          0.9718   \n","19                                          0.9718   \n","20                                          0.9718   \n","\n","    logistic_183_days_10000_samples_70_recall_1  \\\n","0                                        0.0000   \n","1                                        0.2955   \n","2                                        0.8636   \n","3                                        0.9091   \n","4                                        0.9091   \n","5                                        0.8864   \n","6                                        0.8864   \n","7                                        0.8864   \n","8                                        0.8864   \n","9                                        0.8864   \n","10                                       0.8864   \n","11                                       0.8864   \n","12                                       0.8864   \n","13                                       0.8864   \n","14                                       0.9091   \n","15                                       0.9091   \n","16                                       0.9091   \n","17                                       0.9091   \n","18                                       0.9091   \n","19                                       0.9091   \n","20                                       0.9091   \n","\n","    logistic_183_days_10000_samples_70_inverse_weighted_f2  \\\n","0                                              0.2273        \n","1                                              0.4921        \n","2                                              0.9129        \n","3                                              0.9424        \n","4                                              0.9424        \n","5                                              0.9277        \n","6                                              0.9277        \n","7                                              0.9277        \n","8                                              0.9277        \n","9                                              0.9277        \n","10                                             0.9277        \n","11                                             0.9277        \n","12                                             0.9277        \n","13                                             0.9277        \n","14                                             0.9424        \n","15                                             0.9424        \n","16                                             0.9424        \n","17                                             0.9424        \n","18                                             0.9424        \n","19                                             0.9424        \n","20                                             0.9424        \n","\n","    logistic_365_days_10000_samples_90_acc  \\\n","0                                 0.892857   \n","1                                 0.942308   \n","2                                 0.978022   \n","3                                 0.983516   \n","4                                 0.983516   \n","5                                 0.983516   \n","6                                 0.983516   \n","7                                 0.983516   \n","8                                 0.983516   \n","9                                 0.983516   \n","10                                0.983516   \n","11                                0.983516   \n","12                                0.983516   \n","13                                0.983516   \n","14                                0.983516   \n","15                                0.983516   \n","16                                0.983516   \n","17                                0.983516   \n","18                                0.983516   \n","19                                0.983516   \n","20                                0.983516   \n","\n","    logistic_365_days_10000_samples_90_precision_0  \\\n","0                                           0.8929   \n","1                                           0.9393   \n","2                                           0.9760   \n","3                                           0.9819   \n","4                                           0.9819   \n","5                                           0.9819   \n","6                                           0.9819   \n","7                                           0.9819   \n","8                                           0.9819   \n","9                                           0.9819   \n","10                                          0.9819   \n","11                                          0.9819   \n","12                                          0.9819   \n","13                                          0.9819   \n","14                                          0.9819   \n","15                                          0.9819   \n","16                                          0.9819   \n","17                                          0.9819   \n","18                                          0.9819   \n","19                                          0.9819   \n","20                                          0.9819   \n","\n","    logistic_365_days_10000_samples_90_recall_1  \\\n","0                                        0.0000   \n","1                                        0.4615   \n","2                                        0.7949   \n","3                                        0.8462   \n","4                                        0.8462   \n","5                                        0.8462   \n","6                                        0.8462   \n","7                                        0.8462   \n","8                                        0.8462   \n","9                                        0.8462   \n","10                                       0.8462   \n","11                                       0.8462   \n","12                                       0.8462   \n","13                                       0.8462   \n","14                                       0.8462   \n","15                                       0.8462   \n","16                                       0.8462   \n","17                                       0.8462   \n","18                                       0.8462   \n","19                                       0.8462   \n","20                                       0.8462   \n","\n","    logistic_365_days_10000_samples_90_inverse_weighted_f2  \\\n","0                                              0.1046        \n","1                                              0.5676        \n","2                                              0.8467        \n","3                                              0.8862        \n","4                                              0.8862        \n","5                                              0.8862        \n","6                                              0.8862        \n","7                                              0.8862        \n","8                                              0.8862        \n","9                                              0.8862        \n","10                                             0.8862        \n","11                                             0.8862        \n","12                                             0.8862        \n","13                                             0.8862        \n","14                                             0.8862        \n","15                                             0.8862        \n","16                                             0.8862        \n","17                                             0.8862        \n","18                                             0.8862        \n","19                                             0.8862        \n","20                                             0.8862        \n","\n","    logistic_183_days_10000_samples_90_acc  \\\n","0                                 0.873626   \n","1                                 0.950549   \n","2                                 0.989011   \n","3                                 0.994505   \n","4                                 0.994505   \n","5                                 0.994505   \n","6                                 0.994505   \n","7                                 0.994505   \n","8                                 0.994505   \n","9                                 0.994505   \n","10                                0.994505   \n","11                                0.994505   \n","12                                0.994505   \n","13                                0.994505   \n","14                                0.994505   \n","15                                0.994505   \n","16                                0.994505   \n","17                                0.994505   \n","18                                0.994505   \n","19                                0.994505   \n","20                                0.994505   \n","\n","    logistic_183_days_10000_samples_90_precision_0  \\\n","0                                           0.8736   \n","1                                           0.9464   \n","2                                           0.9876   \n","3                                           0.9938   \n","4                                           0.9938   \n","5                                           0.9938   \n","6                                           0.9938   \n","7                                           0.9938   \n","8                                           0.9938   \n","9                                           0.9938   \n","10                                          0.9938   \n","11                                          0.9938   \n","12                                          0.9938   \n","13                                          0.9938   \n","14                                          0.9938   \n","15                                          0.9938   \n","16                                          0.9938   \n","17                                          0.9938   \n","18                                          0.9938   \n","19                                          0.9938   \n","20                                          0.9938   \n","\n","    logistic_183_days_10000_samples_90_recall_1  \\\n","0                                        0.0000   \n","1                                        0.6087   \n","2                                        0.9130   \n","3                                        0.9565   \n","4                                        0.9565   \n","5                                        0.9565   \n","6                                        0.9565   \n","7                                        0.9565   \n","8                                        0.9565   \n","9                                        0.9565   \n","10                                       0.9565   \n","11                                       0.9565   \n","12                                       0.9565   \n","13                                       0.9565   \n","14                                       0.9565   \n","15                                       0.9565   \n","16                                       0.9565   \n","17                                       0.9565   \n","18                                       0.9565   \n","19                                       0.9565   \n","20                                       0.9565   \n","\n","    logistic_183_days_10000_samples_90_inverse_weighted_f2  \\\n","0                                              0.1228        \n","1                                              0.7019        \n","2                                              0.9378        \n","3                                              0.9692        \n","4                                              0.9692        \n","5                                              0.9692        \n","6                                              0.9692        \n","7                                              0.9692        \n","8                                              0.9692        \n","9                                              0.9692        \n","10                                             0.9692        \n","11                                             0.9692        \n","12                                             0.9692        \n","13                                             0.9692        \n","14                                             0.9692        \n","15                                             0.9692        \n","16                                             0.9692        \n","17                                             0.9692        \n","18                                             0.9692        \n","19                                             0.9692        \n","20                                             0.9692        \n","\n","    logistic_365_days_10000_samples_70_acc  \\\n","0                                 0.659341   \n","1                                 0.782967   \n","2                                 0.906593   \n","3                                 0.953297   \n","4                                 0.956044   \n","5                                 0.956044   \n","6                                 0.956044   \n","7                                 0.956044   \n","8                                 0.958791   \n","9                                 0.958791   \n","10                                0.958791   \n","11                                0.958791   \n","12                                0.958791   \n","13                                0.958791   \n","14                                0.956044   \n","15                                0.956044   \n","16                                0.956044   \n","17                                0.956044   \n","18                                0.956044   \n","19                                0.956044   \n","20                                0.956044   \n","\n","    logistic_365_days_10000_samples_70_precision_0  \\\n","0                                           0.6593   \n","1                                           0.7524   \n","2                                           0.8759   \n","3                                           0.9339   \n","4                                           0.9375   \n","5                                           0.9375   \n","6                                           0.9375   \n","7                                           0.9375   \n","8                                           0.9412   \n","9                                           0.9412   \n","10                                          0.9412   \n","11                                          0.9412   \n","12                                          0.9412   \n","13                                          0.9412   \n","14                                          0.9375   \n","15                                          0.9375   \n","16                                          0.9375   \n","17                                          0.9375   \n","18                                          0.9375   \n","19                                          0.9375   \n","20                                          0.9375   \n","\n","    logistic_365_days_10000_samples_70_recall_1  \\\n","0                                        0.0000   \n","1                                        0.3629   \n","2                                        0.7258   \n","3                                        0.8629   \n","4                                        0.8710   \n","5                                        0.8710   \n","6                                        0.8710   \n","7                                        0.8710   \n","8                                        0.8790   \n","9                                        0.8790   \n","10                                       0.8790   \n","11                                       0.8790   \n","12                                       0.8790   \n","13                                       0.8790   \n","14                                       0.8710   \n","15                                       0.8710   \n","16                                       0.8710   \n","17                                       0.8710   \n","18                                       0.8710   \n","19                                       0.8710   \n","20                                       0.8710   \n","\n","    logistic_365_days_10000_samples_70_inverse_weighted_f2  \n","0                                              0.3088       \n","1                                              0.5938       \n","2                                              0.8376       \n","3                                              0.9209       \n","4                                              0.9257       \n","5                                              0.9257       \n","6                                              0.9257       \n","7                                              0.9257       \n","8                                              0.9304       \n","9                                              0.9304       \n","10                                             0.9304       \n","11                                             0.9304       \n","12                                             0.9304       \n","13                                             0.9304       \n","14                                             0.9257       \n","15                                             0.9257       \n","16                                             0.9257       \n","17                                             0.9257       \n","18                                             0.9257       \n","19                                             0.9257       \n","20                                             0.9257       "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["results_df = pd.DataFrame(results, columns=df_columns)\n","results_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defalt threshold 0.1"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["alpha = 0.5\n","final_bin_edges = [300, 573, 588, 596, 603, 609, 615, 620, 624, 628, 631, 634, 637, 640, 644, 647, 650, 653, 656, 659, 663, 668, 673, 679, 689, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9532967032967034\n","Testing Precision 0: 0.9339\n","Testing Recall 1: 0.8629\n","Testing Inverse Weighted F2: 0.9209\n","[[240   0]\n"," [ 17 107]]\n","alpha = 0.9\n","final_bin_edges = [300, 573, 588, 596, 603, 609, 615, 620, 624, 628, 631, 634, 637, 640, 644, 647, 650, 653, 656, 659, 663, 668, 673, 679, 689, 850] \n","\n","Best threshold: 0.1\n","Training Accuracy: 0.9972527472527473\n","Best Training Precision 0: 0.997\n","Best Training Recall 1: 0.9655\n","Best Training Inverse Weighted F2 0.9744\n","[[335   0]\n"," [  1  28]]\n","Testing Accuracy: 0.978021978021978\n","Testing Precision 0: 0.9718\n","Testing Recall 1: 0.9091\n","Testing Inverse Weighted F2: 0.9424\n","[[138   0]\n"," [  4  40]]\n","Testing Accuracy: 0.9835164835164835\n","Testing Precision 0: 0.9819\n","Testing Recall 1: 0.8462\n","Testing Inverse Weighted F2: 0.8862\n","[[325   0]\n"," [  6  33]]\n","Testing Accuracy: 0.9945054945054945\n","Testing Precision 0: 0.9938\n","Testing Recall 1: 0.9565\n","Testing Inverse Weighted F2: 0.9692\n","[[159   0]\n"," [  1  22]]\n","Testing Accuracy: 0.9532967032967034\n","Testing Precision 0: 0.9339\n","Testing Recall 1: 0.8629\n","Testing Inverse Weighted F2: 0.9209\n","[[240   0]\n"," [ 17 107]]\n"]}],"source":["# Array fir storing results\n","results = []\n","\n","# alphas = np.arange(0, 1.05, 0.05)\n","# alphas = [round(alpha, 2) for alpha in alphas]\n","alphas = [0.5, 0.9]\n","\n","for alpha in alphas:  \n","    ########################\n","    ### current solution ###\n","    ########################\n","    result = [dist, num_days, num_samples, alpha]\n","    print(f\"alpha = {alpha}\")\n","\n","    \n","    #######################\n","    ### Multi-objective ###\n","    #######################\n","    # solver.Maximize(solver.Sum((alpha * psi_1_train * x).flatten()) - solver.Sum(((1 - alpha) * psi_0_train * x).flatten()))\n","    \n","    \n","    #########################\n","    ### Invoke the solver ###\n","    #########################\n","    # start_time = process_time()\n","    # status = solver.Solve()\n","    # end_time = process_time()\n","    # solving_time = solving_time\n","    \n","    # result.append(solving_time)\n","    # print(f\"Time for solving: {solving_time} s\")\n","    \n","    \n","    ##########################\n","    ### Print the solution ###\n","    ##########################\n","    # x_solution_value = np.zeros((train_size, train_size))\n","\n","    # for i in range(train_size):\n","    #     for j in range(train_size):\n","    #         if j > i:\n","    #             x_solution_value[i, j] = x[i, j].solution_value()\n","                \n","    final_bin_edges = [300, 573, 588, 596, 603, 609, 615, 620, 624, 628, 631, 634, 637, 640, 644, 647, 650, 653, 656, 659, 663, 668, 673, 679, 689, 850]\n","\n","    # if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n","    #     total_cost = solver.Objective().Value()\n","    #     result.append(total_cost)\n","    #     print(f\"Total cost = {total_cost}\")\n","        \n","    #     objective_0 = np.sum(psi_0_train * x_solution_value)\n","    #     result.append(objective_0)\n","    #     print(f\"Objective_0 = {objective_0}\")\n","        \n","    #     objective_1 = np.sum(psi_1_train * x_solution_value)\n","    #     result.append(objective_1)\n","    #     print(f\"Objective_1 = {objective_1}\", \"\\n\")\n","\n","    #     for i in range(train_size):\n","    #         for j in range(train_size):\n","    #             if j > i and x[i, j].solution_value() == 1:\n","    #                 final_bin_edges.append(i + 300)\n","    #     final_bin_edges.append(max_edge)\n","    # else:\n","    #     print('No solution found.')\n","        \n","    print(\"final_bin_edges =\", final_bin_edges, \"\\n\")\n","              \n","    \n","    ###############\n","    ### Evaluation ###\n","    ###############\n","    # thresholds = np.arange(0.01, 1.01, 0.01)\n","    # thresholds = [round(threshold, 2) for threshold in thresholds]\n","    thresholds = [0.1]\n","              \n","    # Training Acccuracy & F1 & F2\n","    num_days_train = X_train.shape[0]\n","    best_train_threshold = best_train_precision_0 = best_train_recall_1 = best_train_inverse_weighted_f2 = 0\n","    best_y_train_pred = [0] * (num_days_train - 1)\n","    train_acc = train_f1 = 0\n","    \n","    for threshold in thresholds:\n","        y_train_pred = []\n","        \n","        for i in range(num_days_train - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_train[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_train[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","      \n","            if (y_train[i] == 0 and psi < threshold) or (y_train[i] == 1 and psi >= threshold):\n","                y_train_pred.append(y_train[i])\n","            else:\n","                y_train_pred.append(1 - y_train[i])\n","        \n","        train_precision_0, train_recall_1, train_inverse_weighted_f2 = precision_0_recall_1_inverse_weighted_fbeta(y_train, y_train_pred, beta=2.0)\n","        if train_inverse_weighted_f2 > best_train_inverse_weighted_f2:\n","            best_train_inverse_weighted_f2 = train_inverse_weighted_f2\n","            best_train_threshold = threshold\n","            best_train_precision_0 = train_precision_0\n","            best_train_recall_1 = train_recall_1\n","            best_y_train_pred = y_train_pred\n","            train_acc = accuracy_score(y_train, y_train_pred)\n","\n","    print(\"Best threshold:\", best_train_threshold)\n","    result.append(best_train_threshold)\n","\n","    print(\"Training Accuracy:\", train_acc)\n","    result.append(train_acc)\n","\n","    print(\"Best Training Precision 0:\", best_train_precision_0)\n","    result.append(best_train_precision_0)   \n","\n","    print(\"Best Training Recall 1:\", best_train_recall_1)\n","    result.append(best_train_recall_1)\n","\n","    print(\"Best Training Inverse Weighted F2\", best_train_inverse_weighted_f2)\n","    result.append(best_train_inverse_weighted_f2) \n","\n","    print(confusion_matrix(y_train, best_y_train_pred))\n","              \n","    # Testing Acccuracy & F1 & F2\n","    for i in range(len(test_data_paths)):\n","        X_test, y_test = X_test_all[i], y_test_all[i]\n","        num_days_test = X_test.shape[0]\n","        y_test_pred = []\n","\n","        for i in range(num_days_test - 1):\n","            hist_1 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_1.append(np.sum(X_test[i, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_1 = np.array(hist_1)\n","\n","            hist_2 = []\n","            for j in range(len(final_bin_edges) - 1):\n","                hist_2.append(np.sum(X_test[i + 1, final_bin_edges[j] - 300: final_bin_edges[j + 1] - 300]))\n","            hist_2 = np.array(hist_2)\n","\n","            psis = (hist_1 - hist_2) * np.log((hist_1 + epsilon) / (hist_2 + epsilon))\n","            psi = np.sum(psis)\n","\n","            if (y_test[i] == 0 and psi < best_train_threshold) or (y_test[i] == 1 and psi >= best_train_threshold):\n","                y_test_pred.append(y_test[i])\n","            else:\n","                y_test_pred.append(1 - y_test[i])\n","\n","        test_acc = accuracy_score(y_test, y_test_pred)\n","        print(\"Testing Accuracy:\", test_acc)\n","        result.append(test_acc)\n","        \n","        test_precision_0, test_recall_1, test_inverse_weighted_f2 = precision_0_recall_1_inverse_weighted_fbeta(y_test, y_test_pred, beta=2.0)\n","\n","        print(\"Testing Precision 0:\", test_precision_0)\n","        result.append(test_precision_0)   \n","\n","        print(\"Testing Recall 1:\", test_recall_1)\n","        result.append(test_recall_1)\n","\n","        print(\"Testing Inverse Weighted F2:\", test_inverse_weighted_f2)\n","        result.append(test_inverse_weighted_f2)\n","\n","        print(confusion_matrix(y_test, y_test_pred))\n","\n","    results.append(result)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["25"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df_columns = [\"distribution\", \"num_days\", \"num_samples\", \"alpha\", \"best_threshold\",\n","            \"training_acc\", \"training_precision_0\", \"training_recall_1\", \"training_inverse_weighted_f2\"]\n","\n","for i in range(len(test_data_paths)):\n","    df_columns.append(f\"{id2file[i]}_acc\")\n","    df_columns.append(f\"{id2file[i]}_precision_0\")\n","    df_columns.append(f\"{id2file[i]}_recall_1\")\n","    df_columns.append(f\"{id2file[i]}_inverse_weighted_f2\")\n","    \n","len(df_columns)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>distribution</th>\n","      <th>num_days</th>\n","      <th>num_samples</th>\n","      <th>alpha</th>\n","      <th>best_threshold</th>\n","      <th>training_acc</th>\n","      <th>training_precision_0</th>\n","      <th>training_recall_1</th>\n","      <th>training_inverse_weighted_f2</th>\n","      <th>logistic_183_days_10000_samples_70_acc</th>\n","      <th>logistic_183_days_10000_samples_70_precision_0</th>\n","      <th>logistic_183_days_10000_samples_70_recall_1</th>\n","      <th>logistic_183_days_10000_samples_70_inverse_weighted_f2</th>\n","      <th>logistic_365_days_10000_samples_90_acc</th>\n","      <th>logistic_365_days_10000_samples_90_precision_0</th>\n","      <th>logistic_365_days_10000_samples_90_recall_1</th>\n","      <th>logistic_365_days_10000_samples_90_inverse_weighted_f2</th>\n","      <th>logistic_183_days_10000_samples_90_acc</th>\n","      <th>logistic_183_days_10000_samples_90_precision_0</th>\n","      <th>logistic_183_days_10000_samples_90_recall_1</th>\n","      <th>logistic_183_days_10000_samples_90_inverse_weighted_f2</th>\n","      <th>logistic_365_days_10000_samples_70_acc</th>\n","      <th>logistic_365_days_10000_samples_70_precision_0</th>\n","      <th>logistic_365_days_10000_samples_70_recall_1</th>\n","      <th>logistic_365_days_10000_samples_70_inverse_weighted_f2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.5</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.997</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.953297</td>\n","      <td>0.9339</td>\n","      <td>0.8629</td>\n","      <td>0.9209</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>logistic</td>\n","      <td>365</td>\n","      <td>100000</td>\n","      <td>0.9</td>\n","      <td>0.1</td>\n","      <td>0.997253</td>\n","      <td>0.997</td>\n","      <td>0.9655</td>\n","      <td>0.9744</td>\n","      <td>0.978022</td>\n","      <td>0.9718</td>\n","      <td>0.9091</td>\n","      <td>0.9424</td>\n","      <td>0.983516</td>\n","      <td>0.9819</td>\n","      <td>0.8462</td>\n","      <td>0.8862</td>\n","      <td>0.994505</td>\n","      <td>0.9938</td>\n","      <td>0.9565</td>\n","      <td>0.9692</td>\n","      <td>0.953297</td>\n","      <td>0.9339</td>\n","      <td>0.8629</td>\n","      <td>0.9209</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  distribution num_days num_samples  alpha  best_threshold  training_acc  \\\n","0     logistic      365      100000    0.5             0.1      0.997253   \n","1     logistic      365      100000    0.9             0.1      0.997253   \n","\n","   training_precision_0  training_recall_1  training_inverse_weighted_f2  \\\n","0                 0.997             0.9655                        0.9744   \n","1                 0.997             0.9655                        0.9744   \n","\n","   logistic_183_days_10000_samples_70_acc  \\\n","0                                0.978022   \n","1                                0.978022   \n","\n","   logistic_183_days_10000_samples_70_precision_0  \\\n","0                                          0.9718   \n","1                                          0.9718   \n","\n","   logistic_183_days_10000_samples_70_recall_1  \\\n","0                                       0.9091   \n","1                                       0.9091   \n","\n","   logistic_183_days_10000_samples_70_inverse_weighted_f2  \\\n","0                                             0.9424        \n","1                                             0.9424        \n","\n","   logistic_365_days_10000_samples_90_acc  \\\n","0                                0.983516   \n","1                                0.983516   \n","\n","   logistic_365_days_10000_samples_90_precision_0  \\\n","0                                          0.9819   \n","1                                          0.9819   \n","\n","   logistic_365_days_10000_samples_90_recall_1  \\\n","0                                       0.8462   \n","1                                       0.8462   \n","\n","   logistic_365_days_10000_samples_90_inverse_weighted_f2  \\\n","0                                             0.8862        \n","1                                             0.8862        \n","\n","   logistic_183_days_10000_samples_90_acc  \\\n","0                                0.994505   \n","1                                0.994505   \n","\n","   logistic_183_days_10000_samples_90_precision_0  \\\n","0                                          0.9938   \n","1                                          0.9938   \n","\n","   logistic_183_days_10000_samples_90_recall_1  \\\n","0                                       0.9565   \n","1                                       0.9565   \n","\n","   logistic_183_days_10000_samples_90_inverse_weighted_f2  \\\n","0                                             0.9692        \n","1                                             0.9692        \n","\n","   logistic_365_days_10000_samples_70_acc  \\\n","0                                0.953297   \n","1                                0.953297   \n","\n","   logistic_365_days_10000_samples_70_precision_0  \\\n","0                                          0.9339   \n","1                                          0.9339   \n","\n","   logistic_365_days_10000_samples_70_recall_1  \\\n","0                                       0.8629   \n","1                                       0.8629   \n","\n","   logistic_365_days_10000_samples_70_inverse_weighted_f2  \n","0                                             0.9209       \n","1                                             0.9209       "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["results_df = pd.DataFrame(results, columns=df_columns)\n","results_df"]}],"metadata":{"kernelspec":{"display_name":"data_discretization","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"871ce1bc0dd274fbcbdef4ad0365f378d1ced7d5dc441c7b13130107f9334e06"}}},"nbformat":4,"nbformat_minor":4}
